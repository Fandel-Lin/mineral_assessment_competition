{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "import statistics\n",
    "from statistics import median\n",
    "import random\n",
    "\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.stats import beta\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "\n",
    "import geojson\n",
    "import json\n",
    "\n",
    "import colorsys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "#pytesseract.pytesseract.tesseract_cmd = 'C:\\Program Files\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3baaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a949524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593eb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_multiprocessing = True # Always set to True \n",
    "for_each_loop_global = PROCESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_preprocessing = True  # Set to True if map preprocessing is needed\n",
    "\n",
    "crop_legend = True # Always set to True\n",
    "smoothing_map = False # Always set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_intermediate_image = True # create directory and output intermediate images \n",
    "# output for cropped map => 'intermediate6/cropped_map_mask'\n",
    "# output for polygon extraction => 'intermediate7(2)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='eval_data_perfomer' # path to input maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2126818c",
   "metadata": {},
   "source": [
    "# Below is a Preprocessing Step for All Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7107562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir='validation'\n",
    "if not os.path.exists('intermediate6/'):\n",
    "    os.makedirs('intermediate6/')\n",
    "\n",
    "candidate_file_name_for_preprocessing = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if '.json' in file_name:\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "\n",
    "        any_counter = 0\n",
    "\n",
    "        with open(test_json) as f:\n",
    "            gj = json.load(f)\n",
    "        for this_gj in gj['shapes']:\n",
    "            #print(this_gj)\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names and '_pt' not in names and '_line' not in names:\n",
    "                print(names)\n",
    "            any_counter = any_counter+1\n",
    "            break\n",
    "        \n",
    "        if any_counter > 0:\n",
    "            candidate_file_name_for_preprocessing.append(file_name)\n",
    "print(len(candidate_file_name_for_preprocessing))\n",
    "print(candidate_file_name_for_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ffab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('intermediate6/cropped_map'):\n",
    "    os.makedirs('intermediate6/cropped_map')\n",
    "if not os.path.exists('intermediate6/cropped_map_mask'):\n",
    "    os.makedirs('intermediate6/cropped_map_mask')\n",
    "\n",
    "for target_file_q in range(0, len(candidate_file_name_for_preprocessing)):\n",
    "    # get the .tif files\n",
    "    file_name = candidate_file_name_for_preprocessing[target_file_q]\n",
    "\n",
    "    if '.json' in file_name:\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        print('Working on map:', file_name)\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "        \n",
    "        img0 = cv2.imread(file_path)\n",
    "        rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "        gray0 = cv2.cvtColor(img0,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        blank = np.zeros((img0.shape[0],img0.shape[1],img0.shape[2]),dtype=np.uint8)\n",
    "        blank[0:img0.shape[0],0:img0.shape[1],0:img0.shape[2]] = 255\n",
    "\n",
    "        corner_area = np.copy(rgb0[int(rgb0.shape[0]*2/100):int(rgb0.shape[0]*3/100), int(rgb0.shape[1]*30/100):int(rgb0.shape[1]*70/100)])\n",
    "        rgb_trimmed = np.zeros((corner_area.shape[2], corner_area.shape[0], corner_area.shape[1]), dtype='uint8')\n",
    "        for dimension in range(0, 3):\n",
    "            rgb_trimmed[dimension] = np.copy(corner_area[:,:,dimension])\n",
    "\n",
    "        lower_color = np.array([250,250,250]) ### This shall be the color you want to crop off\n",
    "        upper_color = np.array([256,256,256]) ### This shall be the color you want to crop off\n",
    "\n",
    "        res_box = cv2.inRange(rgb0, lower_color, upper_color)\n",
    "\n",
    "        # Either use threshold (less accurate, but works for rotated cases) or contour to remove black border\n",
    "        '''\n",
    "        lower_color = np.array([0,0,0])\n",
    "        upper_color = np.array([1,1,1])\n",
    "\n",
    "        res_box_1 = cv2.inRange(rgb0, lower_color, upper_color)\n",
    "        res_box = cv2.bitwise_or(res_box, res_box_1)\n",
    "        '''\n",
    "        _,thresh = cv2.threshold(gray0,1,255,cv2.THRESH_BINARY)\n",
    "        contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = contours[0]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "        res_box_1 = np.ones((img0.shape[0],img0.shape[1]),dtype=np.uint8)*255\n",
    "        res_box_1[y:y+h,x:x+w] = 0\n",
    "        res_box = cv2.bitwise_or(res_box, res_box_1)\n",
    "        # Either use threshold or contour to remove black border\n",
    "\n",
    "\n",
    "        res_box[res_box < 255] = 0\n",
    "        img_bw00 = 255 - res_box\n",
    "\n",
    "        # remove moisy white pixels before buffer\n",
    "        kernel_before_blur00 = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        opening_before_blur00 = cv2.morphologyEx(img_bw00, cv2.MORPH_OPEN, kernel_before_blur00, iterations=1)\n",
    "\n",
    "        # smooth the image\n",
    "        blur_radius = 5.0\n",
    "        threshold_blur = 0\n",
    "        gaussian_buffer00 = ndimage.gaussian_filter(opening_before_blur00, blur_radius)\n",
    "        gaussian_buffer00[gaussian_buffer00 > threshold_blur] = 255\n",
    "\n",
    "        # find connected components\n",
    "        labeled00, nr_objects00 = ndimage.label(gaussian_buffer00 > threshold_blur)\n",
    "\n",
    "        label_area = np.bincount(labeled00.flat)[1:] # 1\n",
    "        arg_sort = np.argsort(label_area)\n",
    "\n",
    "        check_generated = False\n",
    "        threshold = [0.4, 0.3, 0.2, 0.1, 0.05]\n",
    "        max_variety = 0\n",
    "        for relaxing_threshold in range(0, len(threshold)):\n",
    "            for target_arg in range(arg_sort.shape[0]-1, arg_sort.shape[0]-6, -1): # Only check the top-5 largest regions\n",
    "                #print(target_arg, arg_sort[target_arg])\n",
    "                selected_index = arg_sort[target_arg]+1 # 1\n",
    "\n",
    "                selected_map_for_examination = np.zeros((labeled00.shape[0],labeled00.shape[1],1),dtype=np.uint8)\n",
    "                selected_map_for_examination[labeled00 == selected_index] = 255\n",
    "                \n",
    "                # need to check\n",
    "                crop_rgb0 = cv2.bitwise_and(rgb0,rgb0, mask=selected_map_for_examination)\n",
    "                uniques = np.unique(crop_rgb0)\n",
    "                if uniques.shape[0] > max_variety:\n",
    "                    max_variety = uniques.shape[0]\n",
    "                \n",
    "                if uniques.shape[0] > 255*threshold[relaxing_threshold] or (relaxing_threshold > 0 and uniques.shape[0] == max_variety):\n",
    "                    check_generated = True\n",
    "                    break\n",
    "            if check_generated:\n",
    "                break\n",
    "        \n",
    "        if crop_legend == True:\n",
    "            legend_mask = np.ones((img0.shape[0], img0.shape[1]), dtype='uint8') *255\n",
    "            with open(test_json) as f:\n",
    "                gj = json.load(f)\n",
    "            for this_gj in gj['shapes']:\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0])\n",
    "                y_max = int(np.max(geoms, axis=0)[0])\n",
    "                x_min = int(np.min(geoms, axis=0)[1])\n",
    "                x_max = int(np.max(geoms, axis=0)[1])\n",
    "                legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "            selected_map_for_examination = cv2.bitwise_and(selected_map_for_examination, legend_mask)\n",
    "\n",
    "        if check_generated == False:\n",
    "            selected_map_for_examination = np.ones((img0.shape[0],img0.shape[1],1),dtype=np.uint8)*255\n",
    "            crop_rgb2 = np.copy(rgb0)\n",
    "        else:\n",
    "            blank_mask = cv2.bitwise_and(blank, blank, mask=cv2.bitwise_not(selected_map_for_examination))\n",
    "            crop_rgb2 = cv2.add(crop_rgb0, blank_mask)\n",
    "\n",
    "        # remove gray header\n",
    "        header_region = np.copy(rgb0)\n",
    "        header_region = header_region[0:int(rgb0.shape[0]*0.06),:]\n",
    "        header_included = selected_map_for_examination[0:int(rgb0.shape[0]*0.06),:]\n",
    "\n",
    "        lower_color = np.array([210,210,210]) ### This shall be the color you want to crop off\n",
    "        upper_color = np.array([250,250,250]) ### This shall be the color you want to crop off\n",
    "        header_gray = cv2.inRange(header_region, lower_color, upper_color)\n",
    "\n",
    "        if np.sum(header_gray)/np.sum(header_included) > 0.85:\n",
    "            print('remove gray header')\n",
    "            selected_map_for_examination[0:int(rgb0.shape[0]*0.06),:] = 0\n",
    "\n",
    "        out_file_path0='intermediate6/cropped_map_mask/'+file_name.replace('.json', '')+'_expected_crop_region.tif'\n",
    "        cv2.imwrite(out_file_path0, selected_map_for_examination)\n",
    "        \n",
    "        \n",
    "        plt.imshow(crop_rgb2)\n",
    "        plt.show()\n",
    "\n",
    "        print_bgr = cv2.cvtColor(crop_rgb2, cv2.COLOR_RGB2BGR)\n",
    "        out_file_path0='intermediate6/cropped_map/'+file_name.replace('.json', '')+'_crop.tif'\n",
    "        cv2.imwrite(out_file_path0, print_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211b7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b118036",
   "metadata": {},
   "source": [
    "# Belows are for Polygon Extraction Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc0d91",
   "metadata": {},
   "source": [
    "### Specify which maps to extract (map with polygon features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_file_name_for_polygon = []\n",
    "poly_legend_counter = []\n",
    "#poly_legend_counter_v2 = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if '.json' in file_name:\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        #print('Working on map:', file_name)\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "        \n",
    "        poly_counter = 0\n",
    "        legend_counter = 0\n",
    "        poly_name_list = []\n",
    "\n",
    "        with open(test_json) as f:\n",
    "            gj = json.load(f)\n",
    "        for this_gj in gj['shapes']:\n",
    "            #print(this_gj)\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names and '_pt' not in names and '_line' not in names:\n",
    "                print(names)\n",
    "            if '_poly' not in names:\n",
    "                continue\n",
    "            if names not in poly_name_list:\n",
    "                poly_name_list.append(names)\n",
    "            legend_counter = legend_counter + 1\n",
    "            \n",
    "        if legend_counter > 0:\n",
    "            poly_counter = poly_counter + 1\n",
    "            poly_legend_counter.append(len(poly_name_list))\n",
    "            #poly_legend_counter.append(legend_counter)\n",
    "            #poly_legend_counter_v2.append(len(poly_name_list))\n",
    "        \n",
    "        if poly_counter > 0:\n",
    "            candidate_file_name_for_polygon.append(file_name)\n",
    "print(len(candidate_file_name_for_polygon))\n",
    "print(candidate_file_name_for_polygon)\n",
    "print(poly_legend_counter)\n",
    "#print(poly_legend_counter_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95e6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1e07fa8",
   "metadata": {},
   "source": [
    "### Preprocessing for the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f4480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_dir='validation'\n",
    "if not os.path.exists('intermediate7/'):\n",
    "    os.makedirs('intermediate7/')\n",
    "\n",
    "\n",
    "if map_preprocessing == True:\n",
    "    runningtime_start=datetime.now()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def preprocessing(map_id):\n",
    "        file_name = candidate_file_name_for_polygon[map_id]\n",
    "        \n",
    "        \n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        print('Working on map:', file_name)\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "        \n",
    "        img0 = cv2.imread(file_path)\n",
    "        hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "        rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "        gray0 = cv2.cvtColor(img0,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        lower_black = np.array([0,0,0])\n",
    "        upper_black = np.array([130,130,130]) #100\n",
    "\n",
    "        blank = np.zeros((img0.shape[0],img0.shape[1],img0.shape[2]),dtype=np.uint8)\n",
    "        blank[0:img0.shape[0],0:img0.shape[1],0:img0.shape[2]]=255\n",
    "\n",
    "        # create a mask to only preserve current legend color in the basemap\n",
    "        mask_box = cv2.inRange(rgb0, lower_black, upper_black)\n",
    "        res_box = cv2.bitwise_and(blank,blank, mask=mask_box)\n",
    "\n",
    "        # convert to grayscale \n",
    "        detected_gray0 = cv2.cvtColor(res_box, cv2.COLOR_BGR2GRAY)\n",
    "        img_bw0 = cv2.threshold(detected_gray0, 60, 255, cv2.THRESH_BINARY)[1] # 127\n",
    "\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_blackregion.png'\n",
    "        cv2.imwrite(out_file_path0, img_bw0)\n",
    "\n",
    "\n",
    "\n",
    "        lower_black1 = np.array([100,100,100])\n",
    "        upper_black1 = np.array([180,180,180])\n",
    "\n",
    "        # create a mask to only preserve current legend color in the basemap\n",
    "        mask_box1 = cv2.inRange(rgb0, lower_black1, upper_black1)\n",
    "        res_box1 = cv2.bitwise_and(blank,blank, mask=mask_box1)\n",
    "\n",
    "        # convert to grayscale \n",
    "        detected_gray1 = cv2.cvtColor(res_box1, cv2.COLOR_BGR2GRAY)\n",
    "        img_bw01 = cv2.threshold(detected_gray1, 60, 255, cv2.THRESH_BINARY)[1] # 127\n",
    "\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_grayregion.png'\n",
    "        cv2.imwrite(out_file_path0, img_bw01)\n",
    "\n",
    "\n",
    "\n",
    "        blank = np.zeros((img0.shape[0],img0.shape[1],img0.shape[2]),dtype=np.uint8)\n",
    "        blank[0:img0.shape[0],0:img0.shape[1],0:img0.shape[2]] = 255\n",
    "\n",
    "        corner_area = np.copy(rgb0[int(rgb0.shape[0]*2/100):int(rgb0.shape[0]*3/100), int(rgb0.shape[1]*30/100):int(rgb0.shape[1]*70/100)])\n",
    "        rgb_trimmed = np.zeros((corner_area.shape[2], corner_area.shape[0], corner_area.shape[1]), dtype='uint8')\n",
    "        for dimension in range(0, 3):\n",
    "            rgb_trimmed[dimension] = np.copy(corner_area[:,:,dimension])\n",
    "\n",
    "        lower_color = np.array([250,250,250]) ### This shall be the color you want to crop off\n",
    "        upper_color = np.array([256,256,256]) ### This shall be the color you want to crop off\n",
    "\n",
    "        res_box = cv2.inRange(rgb0, lower_color, upper_color)\n",
    "\n",
    "        # Either use threshold (less accurate, but works for rotated cases) or contour to remove black border\n",
    "        '''\n",
    "        lower_color = np.array([0,0,0])\n",
    "        upper_color = np.array([1,1,1])\n",
    "\n",
    "        res_box_1 = cv2.inRange(rgb0, lower_color, upper_color)\n",
    "        res_box = cv2.bitwise_or(res_box, res_box_1)\n",
    "        '''\n",
    "        _,thresh = cv2.threshold(gray0,1,255,cv2.THRESH_BINARY)\n",
    "        contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = contours[0]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "        res_box_1 = np.ones((img0.shape[0],img0.shape[1]),dtype=np.uint8)*255\n",
    "        res_box_1[y:y+h,x:x+w] = 0\n",
    "        res_box = cv2.bitwise_or(res_box, res_box_1)\n",
    "        # Either use threshold or contour to remove black border\n",
    "\n",
    "\n",
    "        res_box[res_box < 255] = 0\n",
    "        img_bw00 = 255 - res_box\n",
    "\n",
    "        # remove moisy white pixels before buffer\n",
    "        kernel_before_blur00 = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        opening_before_blur00 = cv2.morphologyEx(img_bw00, cv2.MORPH_OPEN, kernel_before_blur00, iterations=1)\n",
    "\n",
    "        # smooth the image\n",
    "        blur_radius = 5.0\n",
    "        threshold_blur = 0\n",
    "        gaussian_buffer00 = ndimage.gaussian_filter(opening_before_blur00, blur_radius)\n",
    "        gaussian_buffer00[gaussian_buffer00 > threshold_blur] = 255\n",
    "\n",
    "        # find connected components\n",
    "        labeled00, nr_objects00 = ndimage.label(gaussian_buffer00 > threshold_blur)\n",
    "\n",
    "        label_area = np.bincount(labeled00.flat)[1:] # 1\n",
    "        arg_sort = np.argsort(label_area)\n",
    "\n",
    "        check_generated = False\n",
    "        threshold = [0.4, 0.3, 0.2, 0.1, 0.05]\n",
    "        temp_max = 0\n",
    "        for relaxing_threshold in range(0, len(threshold)):\n",
    "            for target_arg in range(arg_sort.shape[0]-1, arg_sort.shape[0]-6, -1):\n",
    "                #print(target_arg, arg_sort[target_arg])\n",
    "                selected_index = arg_sort[target_arg]+1 # 1\n",
    "\n",
    "                selected_map_for_examination = np.zeros((labeled00.shape[0],labeled00.shape[1],1),dtype=np.uint8)\n",
    "                selected_map_for_examination[labeled00 == selected_index] = 255\n",
    "                \n",
    "                # need to check\n",
    "                crop_rgb0 = cv2.bitwise_and(rgb0,rgb0, mask=selected_map_for_examination)\n",
    "                uniques = np.unique(crop_rgb0)\n",
    "                #print(uniques.shape[0])\n",
    "                if uniques.shape[0] > temp_max:\n",
    "                    temp_max = uniques.shape[0]\n",
    "                \n",
    "                if uniques.shape[0] > 255*threshold[relaxing_threshold] or (relaxing_threshold > 0 and uniques.shape[0] == temp_max):\n",
    "                    check_generated = True\n",
    "                    break\n",
    "            if check_generated:\n",
    "                break\n",
    "        \n",
    "        if crop_legend == True:\n",
    "            legend_mask = np.ones((img0.shape[0], img0.shape[1]), dtype='uint8') *255\n",
    "            with open(test_json) as f:\n",
    "                gj = json.load(f)\n",
    "            for this_gj in gj['shapes']:\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0])\n",
    "                y_max = int(np.max(geoms, axis=0)[0])\n",
    "                x_min = int(np.min(geoms, axis=0)[1])\n",
    "                x_max = int(np.max(geoms, axis=0)[1])\n",
    "                legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "            selected_map_for_examination = cv2.bitwise_and(selected_map_for_examination, legend_mask)\n",
    "        \n",
    "        if check_generated == False:\n",
    "            selected_map_for_examination = np.ones((img0.shape[0],img0.shape[1],1),dtype=np.uint8)*255\n",
    "\n",
    "            crop_rgb2 = np.copy(rgb0)\n",
    "        else:\n",
    "            # remove gray header\n",
    "            header_region = np.copy(rgb0)\n",
    "            header_region = header_region[0:int(rgb0.shape[0]*0.06),:]\n",
    "            header_included = selected_map_for_examination[0:int(rgb0.shape[0]*0.06),:]\n",
    "\n",
    "            lower_color = np.array([210,210,210]) ### This shall be the color you want to crop off\n",
    "            upper_color = np.array([250,250,250]) ### This shall be the color you want to crop off\n",
    "            header_gray = cv2.inRange(header_region, lower_color, upper_color)\n",
    "\n",
    "            if np.sum(header_included) > 0 and np.sum(header_gray)/np.sum(header_included) > 0.85:\n",
    "                print('remove gray header')\n",
    "                selected_map_for_examination[0:int(rgb0.shape[0]*0.06),:] = 0\n",
    "            \n",
    "            blank_mask = cv2.bitwise_and(blank, blank, mask=cv2.bitwise_not(selected_map_for_examination))\n",
    "            crop_rgb2 = cv2.add(crop_rgb0, blank_mask)\n",
    "        #plt.imshow(crop_rgb2)\n",
    "        #plt.show()\n",
    "        \n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif'\n",
    "        cv2.imwrite(out_file_path0, selected_map_for_examination)\n",
    "\n",
    "        print_bgr = cv2.cvtColor(crop_rgb2, cv2.COLOR_RGB2BGR)\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_crop.tif'\n",
    "        cv2.imwrite(out_file_path0, print_bgr)\n",
    "\n",
    "\n",
    "        #img_bw0_arg = np.argwhere(img_bw0 == 255)\n",
    "        #print(img_bw0_arg.shape)\n",
    "\n",
    "        img1 = np.copy(img0)\n",
    "        rgb1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "        hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
    "        #print(rgb1.shape)\n",
    "        '''\n",
    "        crop_rgb1 = rgb1\n",
    "        crop_img_bw0 = img_bw0\n",
    "        crop_img_bw01 = img_bw01\n",
    "        '''\n",
    "        #print(rgb1.shape)\n",
    "        #print(selected_map_for_examination.shape)\n",
    "\n",
    "        \n",
    "        #crop_rgb1 = cv2.bitwise_and(rgb1,rgb1, mask=selected_map_for_examination)\n",
    "        crop_rgb1 = np.copy(crop_rgb2)\n",
    "        crop_img_bw0 = cv2.bitwise_and(img_bw0,img_bw0, mask=selected_map_for_examination)\n",
    "        crop_img_bw01 = cv2.bitwise_and(img_bw01,img_bw01, mask=selected_map_for_examination)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #print(crop_rgb1.shape)\n",
    "        plt.imshow(crop_rgb1)\n",
    "\n",
    "        print_bgr = cv2.cvtColor(crop_rgb1, cv2.COLOR_RGB2BGR)\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_crop.png'\n",
    "        cv2.imwrite(out_file_path0, print_bgr)\n",
    "        #break\n",
    "\n",
    "        img_bw0_arg = np.argwhere(crop_img_bw0 == 255)\n",
    "        #print(img_bw0_arg.shape)\n",
    "\n",
    "        \n",
    "        #plt.imshow(crop_img_bw01)\n",
    "        #plt.show()\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png'\n",
    "        cv2.imwrite(out_file_path0, crop_img_bw01)\n",
    "\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png'\n",
    "        cv2.imwrite(out_file_path0, crop_img_bw0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        trans_hsv1 = cv2.cvtColor(crop_rgb1, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        print_bgr = cv2.cvtColor(crop_rgb1, cv2.COLOR_RGB2BGR)\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_remove_black.png'\n",
    "        cv2.imwrite(out_file_path0, print_bgr)\n",
    "\n",
    "\n",
    "        # without mean shift (for rgb)\n",
    "        trans_rgb0 = cv2.cvtColor(trans_hsv1, cv2.COLOR_HSV2RGB)\n",
    "        trans_hsv0 = cv2.cvtColor(trans_rgb0, cv2.COLOR_RGB2HSV)\n",
    "        #crop_rgb1 = np.copy(trans_rgb0)\n",
    "        #trans_hsv1 = np.copy(trans_hsv0)\n",
    "        \n",
    "        # mean shift (for rgb and hsv)\n",
    "        spatialRadius = 10\n",
    "        colorRadius = 25\n",
    "        maxPyramidLevel = 2\n",
    "\n",
    "        img = cv2.imread('intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "        img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img_rgb_part = cv2.bitwise_and(img_rgb, img_rgb, mask=selected_map_for_examination)\n",
    "        \n",
    "\n",
    "        result = cv2.pyrMeanShiftFiltering(img_rgb, spatialRadius, colorRadius, maxPyramidLevel)\n",
    "\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        crop_rgb1 = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "        trans_hsv1 = cv2.cvtColor(crop_rgb1, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        out_file_path0='intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png'\n",
    "        cv2.imwrite(out_file_path0, result)\n",
    "        \n",
    "        return selected_map_for_examination\n",
    "    \n",
    "    \n",
    "    # multiprocessing_preprocessing\n",
    "    with multiprocessing.Pool(int(PROCESSES/2)) as pool:\n",
    "        multiprocessing_results = [pool.apply_async(preprocessing, (this_map,)) for this_map in range(0, len(candidate_file_name_for_polygon))]\n",
    "\n",
    "        for this_map in multiprocessing_results:\n",
    "            this_crop_map = this_map.get()\n",
    "            plt.imshow(this_crop_map)\n",
    "            plt.show()\n",
    "    \n",
    "    \n",
    "    print('time check _v00:', datetime.now()-runningtime_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c191c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(given_size):\n",
    "    sliding_window_size = given_size\n",
    "    initial_mask = np.zeros((sliding_window_size*2+3,sliding_window_size*2+3), dtype=int)\n",
    "    center_j = sliding_window_size+1\n",
    "    center_i = sliding_window_size+1\n",
    "    initial_mask[center_j-1:center_j+2, center_i-1:center_i+2] = -1\n",
    "\n",
    "    initial_mask[center_j-3][center_i-1] = 2\n",
    "    initial_mask[center_j-3][center_i+1] = 2\n",
    "    initial_mask[center_j-2][center_i] = 2\n",
    "\n",
    "    initial_mask[center_j-1][center_i+3] = 4\n",
    "    initial_mask[center_j+1][center_i+3] = 4\n",
    "    initial_mask[center_j][center_i+2] = 4\n",
    "\n",
    "    initial_mask[center_j+3][center_i-1] = 6\n",
    "    initial_mask[center_j+3][center_i+1] = 6\n",
    "    initial_mask[center_j+2][center_i] = 6\n",
    "\n",
    "    initial_mask[center_j-1][center_i-3] = 8\n",
    "    initial_mask[center_j+1][center_i-3] = 8\n",
    "    initial_mask[center_j][center_i-2] = 8\n",
    "\n",
    "\n",
    "    for j in range(0, sliding_window_size-1):\n",
    "        for i in range(center_i-(sliding_window_size-2-j), center_i+(sliding_window_size-2-j)+1):\n",
    "            initial_mask[j][i] = 2\n",
    "\n",
    "    for j in range(sliding_window_size+3+1, sliding_window_size*2+3):\n",
    "        for i in range(center_i-(j-(sliding_window_size+3+1)), center_i+(j-(sliding_window_size+3+1))+1):\n",
    "            initial_mask[i][j] = 4\n",
    "\n",
    "    for j in range(sliding_window_size+3+1, sliding_window_size*2+3):\n",
    "        for i in range(center_i-(j-(sliding_window_size+3+1)), center_i+(j-(sliding_window_size+3+1))+1):\n",
    "            initial_mask[j][i] = 6\n",
    "\n",
    "    for j in range(0, sliding_window_size-1):\n",
    "        for i in range(center_i-(sliding_window_size-2-j), center_i+(sliding_window_size-2-j)+1):\n",
    "            initial_mask[i][j] = 8\n",
    "\n",
    "    initial_mask_arg = np.argwhere(initial_mask == 0)\n",
    "    for i, j in initial_mask_arg:\n",
    "        if i<=sliding_window_size and j<=sliding_window_size:\n",
    "            initial_mask[i][j] = 1\n",
    "        elif i<=sliding_window_size and j>=sliding_window_size:\n",
    "            initial_mask[i][j] = 3\n",
    "        elif i>=sliding_window_size and j>sliding_window_size:\n",
    "            initial_mask[i][j] = 5\n",
    "        elif i>=sliding_window_size and j<=sliding_window_size:\n",
    "            initial_mask[i][j] = 7\n",
    "    #print(initial_mask)\n",
    "\n",
    "\n",
    "    masking = []\n",
    "    for direction in range(0, 8):\n",
    "        masking.append(np.zeros((sliding_window_size*2+3,sliding_window_size*2+3), dtype=bool))\n",
    "    masking = np.array(masking)\n",
    "\n",
    "    for direction in range(0, 8):\n",
    "        initial_mask_arg = np.argwhere(initial_mask == (direction+1))\n",
    "        for i, j in initial_mask_arg:\n",
    "            masking[direction][i][j] = True\n",
    "    #print(masking.shape)\n",
    "\n",
    "    return masking\n",
    "\n",
    "def kernel_assign_white(img, i, j):\n",
    "    img[max(i-1, 0)][max(j-1, 0)] = 255\n",
    "    img[max(i-1, 0)][j] = 255\n",
    "    img[max(i-1, 0)][min(j+1, 0)] = 255\n",
    "    img[i][max(j-1, 0)] = 255\n",
    "    img[i][j] = 255\n",
    "    img[i][min(j+1, 0)] = 255\n",
    "    img[min(i+1, 0)][max(j-1, 0)] = 255\n",
    "    img[min(i+1, 0)][j] = 255\n",
    "    img[min(i+1, 0)][min(j+1, 0)] = 255\n",
    "\n",
    "def center_assign_white(img, i, j):\n",
    "    img[i][j] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ffe69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97487110",
   "metadata": {},
   "source": [
    "### Attempt to polygon extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec7d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_dir='validation'\n",
    "if not os.path.exists('intermediate7(2)/'):\n",
    "    os.makedirs('intermediate7(2)/')\n",
    "for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "    \n",
    "    running_time_v = []\n",
    "    \n",
    "    \n",
    "    # get the .tif files\n",
    "    if '.json' in file_name:\n",
    "        runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        print('Working on map:', file_name)\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "        file_name_json = test_json.replace('.json', '.json')\n",
    "        \n",
    "        #print(test_json)\n",
    "        img000 = cv2.imread(file_path)\n",
    "        #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "        #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "        img_bound = cv2.imread('intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "        img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_crop_gray = cv2.imread('intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "        img_crop_black = cv2.imread('intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "        img_crop_gray = cv2.cvtColor(img_crop_gray, cv2.COLOR_BGR2GRAY)\n",
    "        img_crop_black = cv2.cvtColor(img_crop_black, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_rb = cv2.imread('intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "        img_ms = cv2.imread('intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png')\n",
    "\n",
    "\n",
    "        with open(file_name_json) as f:\n",
    "            gj = json.load(f)\n",
    "        json_height = gj['imageHeight']\n",
    "        json_width = gj['imageWidth']\n",
    "        rescale_factor_0 = 1.0\n",
    "        rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "        ## Non-white background\n",
    "        non_white_background = False\n",
    "        if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "            lower_white = np.array([250,250,250])\n",
    "            upper_white = np.array([256,256,256])\n",
    "            mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "            lower_white = np.array([0,0,0])\n",
    "            upper_white = np.array([130,130,130])\n",
    "            mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "            mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "            corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "            corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "            if corner_avg_white / corner_area < 0.66:\n",
    "                non_white_background = True\n",
    "                print('non_white_background')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        ### Legend is always not considered\n",
    "        if True:\n",
    "            for this_gj in gj['shapes']:\n",
    "                #print(this_gj)\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                legend_mask = np.ones((img_rb.shape[0], img_rb.shape[1]), dtype='uint8') *255\n",
    "                legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "                img_bound = cv2.bitwise_and(img_bound, legend_mask)\n",
    "            img_rb = cv2.bitwise_and(img_rb, img_rb, mask=img_bound)\n",
    "            img_ms = cv2.bitwise_and(img_ms, img_ms, mask=img_bound)\n",
    "            img_crop_gray = cv2.bitwise_and(img_crop_gray, img_crop_gray, mask=img_bound)\n",
    "            img_crop_black = cv2.bitwise_and(img_crop_black, img_crop_black, mask=img_bound)\n",
    "        hsv_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2HSV)\n",
    "        rgb_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2RGB)\n",
    "        hsv_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2HSV)\n",
    "        rgb_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        poly_counter = 0\n",
    "        color_space = []\n",
    "        color_avg = []\n",
    "        map_name = file_name.replace('.json', '')\n",
    "        legend_name = []\n",
    "        legend_name_check = []\n",
    "        extracted_legend_name = []\n",
    "\n",
    "\n",
    "        hsv_space = np.zeros((255), dtype='uint8') # only for h space\n",
    "        rgb_space = np.zeros((255,255,3), dtype='uint8')\n",
    "\n",
    "\n",
    "        if not os.path.exists('intermediate7(2)/'+map_name):\n",
    "            os.makedirs('intermediate7(2)/'+map_name)\n",
    "\n",
    "\n",
    "        for this_gj in gj['shapes']:\n",
    "            #if '_poly' not in names:\n",
    "                #continue\n",
    "            #print(this_gj)\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names:\n",
    "                continue\n",
    "            if names in legend_name_check:\n",
    "                continue\n",
    "            legend_name_check.append(names)\n",
    "            legend_name.append(names.replace('_poly',''))\n",
    "\n",
    "            poly_counter = poly_counter+1\n",
    "\n",
    "\n",
    "            ### There is no groundtruth for validation data\n",
    "            #print('training/'+map_name+'_'+names+'.tif')\n",
    "\n",
    "\n",
    "            ### Read json source for the legend\n",
    "            geoms = np.array(features)\n",
    "            y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "            y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "            x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "            x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "            img_legend = np.zeros((x_max-x_min, y_max-y_min, 3), dtype='uint8')\n",
    "            img_legend = np.copy(img000[x_min:x_max, y_min:y_max, :])\n",
    "            \n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+names+'_legend.tif'\n",
    "                cv2.imwrite(out_file_path0, img_legend)\n",
    "            \n",
    "            \n",
    "            img_legend = cv2.cvtColor(img_legend, cv2.COLOR_BGR2RGB)\n",
    "            img_legend = img_legend[int(img_legend.shape[0]/8):int(img_legend.shape[0]*7/8), int(img_legend.shape[1]/8):int(img_legend.shape[1]*7/8), :]\n",
    "            hsv_legend = cv2.cvtColor(img_legend, cv2.COLOR_RGB2HSV)\n",
    "            black_threshold = 30 #130\n",
    "            white_threshold = 250 #245\n",
    "\n",
    "            lower_black_rgb_trimmed0 = np.array([0,0,0])\n",
    "            upper_black_rgb_trimmed0 = np.array([130,130,130])\n",
    "            mask_test_img_legend = cv2.inRange(img_legend, lower_black_rgb_trimmed0, upper_black_rgb_trimmed0)\n",
    "            if np.sum(mask_test_img_legend == 255) > np.sum(img_legend > 0) * 0.25:\n",
    "                black_threshold = 30\n",
    "            \n",
    "            rgb_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "            hsv_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "            rgb_trimmed = rgb_trimmed.astype(float)\n",
    "            hsv_trimmed = hsv_trimmed.astype(float)\n",
    "            for dimension in range(0, 3):\n",
    "                rgb_trimmed[dimension] = np.copy(img_legend[:,:,dimension]).astype(float)\n",
    "                hsv_trimmed[dimension] = np.copy(hsv_legend[:,:,dimension]).astype(float)\n",
    "\n",
    "            rgb_trimmed_temp = np.copy(rgb_trimmed)\n",
    "            rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "\n",
    "            rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "            if np.sum(np.isnan(hsv_trimmed)) >= (hsv_trimmed.shape[0]*hsv_trimmed.shape[1]*hsv_trimmed.shape[2]):\n",
    "                color_space_holder = []\n",
    "                rgb_lower_box = np.array((0,0,0), dtype='uint8')\n",
    "                rgb_upper_box = np.array((0,0,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "\n",
    "                color_avg_holder = np.array((0,0,0), dtype='uint8')\n",
    "            else:\n",
    "                color_space_holder = []\n",
    "                hsv_lower_box = np.array([int(np.nanquantile(hsv_trimmed[0],.2)),int(np.nanquantile(hsv_trimmed[1],.1)),int(np.nanquantile(hsv_trimmed[2],.1))]) #.2\n",
    "                hsv_upper_box = np.array([int(np.nanquantile(hsv_trimmed[0],.8)),int(np.nanquantile(hsv_trimmed[1],.9)),int(np.nanquantile(hsv_trimmed[2],.9))]) #.8\n",
    "                color_space_holder.append(hsv_lower_box)\n",
    "                color_space_holder.append(hsv_upper_box)\n",
    "                hsv_space[int(np.nanquantile(hsv_trimmed[0],.2)): int(np.nanquantile(hsv_trimmed[0],.8))] += poly_counter\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.2)),int(np.nanquantile(rgb_trimmed[1],.2)),int(np.nanquantile(rgb_trimmed[2],.2))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.8)),int(np.nanquantile(rgb_trimmed[1],.8)),int(np.nanquantile(rgb_trimmed[2],.8))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_space[int(np.nanquantile(rgb_trimmed[0],.3)): int(np.nanquantile(rgb_trimmed[0],.7)), int(np.nanquantile(rgb_trimmed[1],.3)): int(np.nanquantile(rgb_trimmed[1],.7)), int(np.nanquantile(rgb_trimmed[2],.3)): int(np.nanquantile(rgb_trimmed[2],.7))] = poly_counter\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.15)),int(np.nanquantile(rgb_trimmed[1],.15)),int(np.nanquantile(rgb_trimmed[2],.15))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.85)),int(np.nanquantile(rgb_trimmed[1],.85)),int(np.nanquantile(rgb_trimmed[2],.85))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.1)),int(np.nanquantile(rgb_trimmed[1],.1)),int(np.nanquantile(rgb_trimmed[2],.1))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.9)),int(np.nanquantile(rgb_trimmed[1],.9)),int(np.nanquantile(rgb_trimmed[2],.9))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.06)),int(np.nanquantile(rgb_trimmed[1],.06)),int(np.nanquantile(rgb_trimmed[2],.06))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.94)),int(np.nanquantile(rgb_trimmed[1],.94)),int(np.nanquantile(rgb_trimmed[2],.94))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.02)),int(np.nanquantile(rgb_trimmed[1],.02)),int(np.nanquantile(rgb_trimmed[2],.02))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.98)),int(np.nanquantile(rgb_trimmed[1],.98)),int(np.nanquantile(rgb_trimmed[2],.98))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.01)),int(np.nanquantile(rgb_trimmed[1],.01)),int(np.nanquantile(rgb_trimmed[2],.01))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.99)),int(np.nanquantile(rgb_trimmed[1],.99)),int(np.nanquantile(rgb_trimmed[2],.99))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "\n",
    "                color_avg_holder = np.array([int(np.nanquantile(rgb_trimmed[0],.5)),int(np.nanquantile(rgb_trimmed[1],.5)),int(np.nanquantile(rgb_trimmed[2],.5))])\n",
    "\n",
    "            color_space.append(color_space_holder)\n",
    "            color_avg.append(color_avg_holder)\n",
    "\n",
    "        print('time check _v0:', datetime.now()-runningtime_start)\n",
    "        running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "        ans_category = np.zeros((poly_counter+1, img_rb.shape[0], img_rb.shape[1]), dtype='uint8')\n",
    "\n",
    "        blank = np.ones((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)*255\n",
    "        ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "        #print(legend_name)\n",
    "        #print(color_space)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # If there is color shift for all legends, but this section is never used for the final solution. (smoothing_map always set to False)\n",
    "        if smoothing_map == True:\n",
    "            color_avg.append(np.array([0,0,0]))\n",
    "            #color_avg.append(np.array([255,255,255]))\n",
    "\n",
    "            img_bound_argwhere = np.argwhere(img_bound)\n",
    "            (ystart, xstart), (ystop, xstop) = img_bound_argwhere.min(0), img_bound_argwhere.max(0) + 1 \n",
    "            im = np.copy(rgb_rb[ystart:ystop, xstart:xstop, :])\n",
    "            image = im.reshape(im.shape[0],im.shape[1],1,3)\n",
    "\n",
    "            # Create color container \n",
    "            colors_container = np.ones(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "            for i,color in enumerate(color_avg):\n",
    "                colors_container[:,:,i,:] = color\n",
    "            \n",
    "            rgb_weight = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            rgb_weight[:,:,:,0] = 1 # 2\n",
    "            rgb_weight[:,:,:,1] = 1 # 4\n",
    "            rgb_weight[:,:,:,2] = 1 # 3\n",
    "\n",
    "            background_correction_direct_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            background_correction_direct_rgb[:,:,:,0] = 0.9\n",
    "            background_correction_direct_rgb[:,:,:,1] = 0.9\n",
    "            background_correction_direct_rgb[:,:,:,2] = 0.9\n",
    "\n",
    "            image_deviation = np.zeros(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            image_deviation[:,:,:,0] = image[:,:,:,0] - image[:,:,:,1]\n",
    "            image_deviation[:,:,:,1] = image[:,:,:,0] - image[:,:,:,2]\n",
    "            image_deviation[:,:,:,2] = image[:,:,:,1] - image[:,:,:,2]\n",
    "\n",
    "            legend_deviation = np.zeros(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "            legend_deviation[:,:,:,0] = colors_container[:,:,:,0] - colors_container[:,:,:,1]\n",
    "            legend_deviation[:,:,:,1] = colors_container[:,:,:,0] - colors_container[:,:,:,2]\n",
    "            legend_deviation[:,:,:,2] = colors_container[:,:,:,1] - colors_container[:,:,:,2]\n",
    "            \n",
    "            background_correction_deviated_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            background_correction_deviated_rgb[:,:,:,:] = 0.5 + 0.5*(1.0-abs(image_deviation[:,:,:,:])/255.0)\n",
    "\n",
    "            print('processing _v0 >>> _v1 (finding the closest color)... :', datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "            def closest(image,color_container):\n",
    "                shape = image.shape[:2]\n",
    "                total_shape = shape[0]*shape[1]\n",
    "\n",
    "                # calculate distances\n",
    "                distances_0 = np.sqrt(np.sum(rgb_weight*((color_container*background_correction_direct_rgb-image)**2),axis=3))\n",
    "                distances_1 = np.sqrt(np.sum(((legend_deviation*background_correction_deviated_rgb-image_deviation)**2),axis=3))\n",
    "                distances = distances_0*0.9 + distances_1*0.1\n",
    "\n",
    "                min_index = np.argmin(distances,axis=2).reshape(-1)\n",
    "                natural_index = np.arange(total_shape)\n",
    "\n",
    "                reshaped_container = colors_container.reshape(-1,len(color_avg),3)\n",
    "\n",
    "                color_view = reshaped_container[natural_index,min_index].reshape(shape[0],shape[1],3)\n",
    "                return color_view, distances\n",
    "            \n",
    "            result_image, distances = closest(image,colors_container)\n",
    "            result_image = result_image.astype(np.uint8)\n",
    "\n",
    "            plt.imshow(result_image)\n",
    "            plt.show()\n",
    "            #Image.fromarray(result_image.astype(np.uint8)).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            subtract_rgb = []\n",
    "            \n",
    "            def extraction_step1(legend):\n",
    "                extracted_map = cv2.inRange(result_image, color_avg[legend], color_avg[legend])\n",
    "\n",
    "                distance_threshold = 0\n",
    "                while (np.sum(extracted_map)/255 <= np.sum(img_bound)/255 *0.002):\n",
    "                    distances_v = np.zeros((len(color_avg), image.shape[0], image.shape[1]), dtype='uint8')\n",
    "                    distance_threshold = distance_threshold + 10\n",
    "\n",
    "                    for legend in range(0, poly_counter):\n",
    "                        distances_v[legend] = np.copy(distances[:,:,legend])\n",
    "                        \n",
    "                        extracted_map[distances_v[legend] <= distance_threshold] = 255\n",
    "                        #extracted_map = cv2.bitwise_and(extracted_map, img_bound)\n",
    "                        #ans_category[legend] = cv2.bitwise_or(ans_category[legend], extracted_map)\n",
    "\n",
    "                        print(legend_name[legend])\n",
    "                        plt.imshow(extracted_map)\n",
    "                        plt.show()\n",
    "\n",
    "\n",
    "                extracted_map_v = np.zeros((3, extracted_map.shape[0], extracted_map.shape[1]), dtype='uint8')\n",
    "                extracted_map_v = extracted_map_v.astype(float)\n",
    "                extracted_avg_rgb = []\n",
    "                extracted_lower_rgb = []\n",
    "                extracted_upper_rgb = []\n",
    "\n",
    "                is_null = False\n",
    "                for dimension in range(0, 3):\n",
    "                    extracted_map_v[dimension] = np.copy(im[:,:,dimension]).astype(float)\n",
    "                    extracted_map_v[dimension] = cv2.bitwise_and(im[:,:,dimension], im[:,:,dimension], mask=extracted_map)\n",
    "                    extracted_map_v[dimension] = extracted_map_v[dimension]\n",
    "                    extracted_map_v[dimension][extracted_map_v[dimension] == 0] = np.nan\n",
    "                    if np.sum(np.isnan(extracted_map_v[dimension])) >= (im.shape[0] * im.shape[1]):\n",
    "                        is_null = True\n",
    "                        print('This situation shall not happen.')\n",
    "                    else:\n",
    "                        extracted_avg_rgb.append(int(np.nanquantile(extracted_map_v[dimension],.5)))\n",
    "                        extracted_lower_rgb.append(int(np.nanquantile(extracted_map_v[dimension],.2)))\n",
    "                        extracted_upper_rgb.append(int(np.nanquantile(extracted_map_v[dimension],.8)))\n",
    "                #subtract_rgb.append(color_avg[legend] - extracted_avg_rgb)\n",
    "\n",
    "                rgb_ms_masked = cv2.inRange(rgb_ms, np.array(extracted_lower_rgb), np.array(extracted_upper_rgb))\n",
    "                rgb_rb_masked = cv2.inRange(rgb_rb, np.array(extracted_lower_rgb), np.array(extracted_upper_rgb))\n",
    "                rgb_masked = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "                \n",
    "                img_masked = cv2.bitwise_or(rgb_masked, rgb_masked)\n",
    "                \n",
    "                if print_intermediate_image == True:\n",
    "                    out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v1_rgb.png'\n",
    "                    cv2.imwrite(out_file_path0, rgb_masked)\n",
    "                    out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v2.png'\n",
    "                    cv2.imwrite(out_file_path0, img_masked)\n",
    "                \n",
    "                return legend, img_masked, (color_avg[legend] - extracted_avg_rgb)\n",
    "            \n",
    "            \n",
    "            # multiprocessing_step1\n",
    "            with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                multiprocessing_results = [pool.apply_async(extraction_step1, (this_poly,)) for this_poly in range(0, poly_counter)]\n",
    "\n",
    "                for this_poly in multiprocessing_results:\n",
    "                    legend, img_masked, this_subtract_rgb = this_poly.get()\n",
    "                    # add masked result into private ans_category\n",
    "                    ans_category[legend] = np.copy(img_masked)\n",
    "                    # add mophological result into global ans_category\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                    img_masked_morphology = cv2.morphologyEx(img_masked, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                    img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                    ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "                    \n",
    "                    for space in range(2, len(color_space[legend]), 2):\n",
    "                        color_space[legend][space] = color_space[legend][space] - this_subtract_rgb\n",
    "                        color_space[legend][space+1] = color_space[legend][space+1] - this_subtract_rgb + 1\n",
    "                    \n",
    "            \n",
    "            print('processing _v1 >>> _v2 (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "            result_image0 = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)\n",
    "            out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_nearest.png'\n",
    "            cv2.imwrite(out_file_path0, result_image0)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "            def extraction_step2(legend):\n",
    "                # create a mask to only preserve current legend color in the basemap\n",
    "                hsv_ms_masked = cv2.inRange(hsv_ms, color_space[legend][0], color_space[legend][1])\n",
    "                hsv_rb_masked = cv2.inRange(hsv_rb, color_space[legend][0], color_space[legend][1])\n",
    "                hsv_masked = cv2.bitwise_or(hsv_ms_masked, hsv_rb_masked)\n",
    "\n",
    "                rgb_ms_masked = cv2.inRange(rgb_ms, color_space[legend][2], color_space[legend][3])\n",
    "                rgb_rb_masked = cv2.inRange(rgb_rb, color_space[legend][2], color_space[legend][3])\n",
    "                rgb_masked = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "\n",
    "                img_masked = cv2.bitwise_or(hsv_masked, rgb_masked)\n",
    "\n",
    "\n",
    "                if poly_counter <= 1:\n",
    "                    # dilation if needed\n",
    "                    color_space[legend][0][0] = color_space[legend][0][0] - 20\n",
    "                    color_space[legend][1][0] = color_space[legend][1][0] + 20\n",
    "                    color_space[legend][0][1] = color_space[legend][0][1] - 40\n",
    "                    color_space[legend][1][1] = color_space[legend][1][1] + 40\n",
    "                    color_space[legend][0][2] = color_space[legend][0][2] - 40\n",
    "                    color_space[legend][1][2] = color_space[legend][1][2] + 40\n",
    "                    #print(color_space[legend][0], color_space[legend][1])\n",
    "                    \n",
    "                    hsv_ms_masked = cv2.inRange(hsv_ms, color_space[legend][0], color_space[legend][1])\n",
    "                    hsv_rb_masked = cv2.inRange(hsv_rb, color_space[legend][0], color_space[legend][1])\n",
    "                    hsv_masked = cv2.bitwise_or(hsv_ms_masked, hsv_rb_masked)\n",
    "                    \n",
    "                    while poly_counter <= 1 and (np.sum(rgb_masked)/255 <= np.sum(img_bound)/255 *0.02):\n",
    "                        # dilation if needed\n",
    "                        for rgb_set in range(2, len(color_space[legend]), 2):\n",
    "                            color_space[legend][rgb_set] = color_space[legend][rgb_set] -4\n",
    "                            color_space[legend][rgb_set+1] = color_space[legend][rgb_set+1] +4\n",
    "                        #print(color_space[legend][2], color_space[legend][3])\n",
    "\n",
    "                        rgb_ms_masked = cv2.inRange(rgb_ms, color_space[legend][2], color_space[legend][3])\n",
    "                        rgb_rb_masked = cv2.inRange(rgb_rb, color_space[legend][2], color_space[legend][3])\n",
    "                        rgb_masked = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "\n",
    "                        img_masked = cv2.bitwise_or(hsv_masked, rgb_masked)\n",
    "                    \n",
    "                    # remove noisy white pixel\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (8,8))\n",
    "                    opening = cv2.morphologyEx(img_masked, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                    img_masked=cv2.threshold(opening, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "                        \n",
    "                    if (np.sum(rgb_masked)/255 <= np.sum(img_bound)/255 *0.1):\n",
    "                        for rgb_set in range(len(color_space[legend])-2, len(color_space[legend]), 2):\n",
    "                            color_space[legend][rgb_set] = color_space[legend][rgb_set] -15\n",
    "                            color_space[legend][rgb_set+1] = color_space[legend][rgb_set+1] +15\n",
    "                            \n",
    "                elif poly_counter <= 3:\n",
    "                    # dilation if needed\n",
    "                    color_space[legend][0][0] = color_space[legend][0][0] - 6\n",
    "                    color_space[legend][1][0] = color_space[legend][1][0] + 6\n",
    "                    color_space[legend][0][1] = color_space[legend][0][1] - 20\n",
    "                    color_space[legend][1][1] = color_space[legend][1][1] + 20\n",
    "                    color_space[legend][0][2] = color_space[legend][0][2] - 20\n",
    "                    color_space[legend][1][2] = color_space[legend][1][2] + 20\n",
    "                    #print(color_space[legend][0], color_space[legend][1])\n",
    "\n",
    "                    hsv_ms_masked = cv2.inRange(hsv_ms, color_space[legend][0], color_space[legend][1])\n",
    "                    hsv_rb_masked = cv2.inRange(hsv_rb, color_space[legend][0], color_space[legend][1])\n",
    "                    hsv_masked = cv2.bitwise_or(hsv_ms_masked, hsv_rb_masked)\n",
    "\n",
    "                    rgb_ms_masked = cv2.inRange(rgb_ms, color_space[legend][2], color_space[legend][3])\n",
    "                    rgb_rb_masked = cv2.inRange(rgb_rb, color_space[legend][2], color_space[legend][3])\n",
    "                    rgb_masked = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "\n",
    "                    img_masked = cv2.bitwise_and(hsv_masked, hsv_masked)\n",
    "                elif poly_counter > 3:\n",
    "                    if poly_counter > 3:\n",
    "                        # dilation if needed\n",
    "                        current_h_lower = color_space[legend][0][0]\n",
    "                        current_h_max = 0\n",
    "                        for h_space in range(current_h_lower, -1, -1):\n",
    "                            if hsv_space[h_space] > 0 and hsv_space[h_space] != legend:\n",
    "                                current_h_max = h_space\n",
    "                                break\n",
    "                        \n",
    "                        current_h_upper = color_space[legend][1][0]\n",
    "                        current_h_min = 255\n",
    "                        for h_space in range(current_h_upper, 255):\n",
    "                            if hsv_space[h_space] > 0 and hsv_space[h_space] != legend:\n",
    "                                current_h_min = h_space\n",
    "                                break\n",
    "                        \n",
    "                        color_space[legend][0][0] = current_h_lower - min(int((current_h_lower-current_h_max)/4), 2)\n",
    "                        color_space[legend][1][0] = current_h_upper + min(int((current_h_min-current_h_upper)/4), 2)\n",
    "                        color_space[legend][0][1] = color_space[legend][0][1] - 5\n",
    "                        color_space[legend][1][1] = color_space[legend][1][1] + 5\n",
    "                        color_space[legend][0][2] = color_space[legend][0][2] - 5\n",
    "                        color_space[legend][1][2] = color_space[legend][1][2] + 5\n",
    "                        #print(color_space[legend][0], color_space[legend][1])\n",
    "                        \n",
    "                        hsv_ms_masked = cv2.inRange(hsv_ms, color_space[legend][0], color_space[legend][1])\n",
    "                        hsv_rb_masked = cv2.inRange(hsv_rb, color_space[legend][0], color_space[legend][1])\n",
    "                        hsv_masked = cv2.bitwise_or(hsv_ms_masked, hsv_rb_masked)\n",
    "\n",
    "                        img_masked = cv2.bitwise_or(hsv_masked, rgb_masked)\n",
    "                    \n",
    "                    hsv_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                    hsv_opening = cv2.morphologyEx(hsv_masked, cv2.MORPH_OPEN, hsv_kernel, iterations=1)\n",
    "                    dilation_step = 0\n",
    "                    dilation_step_threshold = 10\n",
    "                    while ((dilation_step<dilation_step_threshold) and (np.sum(hsv_opening)/255 <= np.sum(img_bound)/255 *0.0005)) or ((dilation_step>=dilation_step_threshold) and (np.sum(hsv_masked)/255 <= np.sum(img_bound)/255 *0.0005)):\n",
    "                        # dilation if needed\n",
    "                        current_h_lower = color_space[legend][0][0]\n",
    "                        current_h_max = 0\n",
    "                        for h_space in range(current_h_lower, -1, -1):\n",
    "                            if hsv_space[h_space] > 0 and hsv_space[h_space] != legend:\n",
    "                                current_h_max = h_space\n",
    "                                break\n",
    "                        \n",
    "                        current_h_upper = color_space[legend][1][0]\n",
    "                        current_h_min = 255\n",
    "                        for h_space in range(current_h_upper, 255):\n",
    "                            if hsv_space[h_space] > 0 and hsv_space[h_space] != legend:\n",
    "                                current_h_min = h_space\n",
    "                                break\n",
    "                        \n",
    "                        color_space[legend][0][0] = current_h_lower - min(int((current_h_lower-current_h_max)/4), 2)\n",
    "                        color_space[legend][1][0] = current_h_upper + min(int((current_h_min-current_h_upper)/4), 2)\n",
    "                        color_space[legend][0][1] = color_space[legend][0][1] - 5\n",
    "                        color_space[legend][1][1] = color_space[legend][1][1] + 5\n",
    "                        color_space[legend][0][2] = color_space[legend][0][2] - 5\n",
    "                        color_space[legend][1][2] = color_space[legend][1][2] + 5\n",
    "                        #print(color_space[legend][0], color_space[legend][1])\n",
    "\n",
    "                        hsv_ms_masked = cv2.inRange(hsv_ms, color_space[legend][0], color_space[legend][1])\n",
    "                        hsv_rb_masked = cv2.inRange(hsv_rb, color_space[legend][0], color_space[legend][1])\n",
    "                        hsv_masked = cv2.bitwise_or(hsv_ms_masked, hsv_rb_masked)\n",
    "\n",
    "                        img_masked = cv2.bitwise_or(hsv_masked, rgb_masked)\n",
    "                        \n",
    "                        dilation_step = dilation_step + 1\n",
    "                        \n",
    "                        hsv_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        hsv_opening = cv2.morphologyEx(hsv_masked, cv2.MORPH_OPEN, hsv_kernel, iterations=1)\n",
    "                        \n",
    "                        if (dilation_step >= dilation_step_threshold*3):\n",
    "                            break\n",
    "                            \n",
    "                    if poly_counter < 20 and  (dilation_step >= dilation_step_threshold*3) and (np.sum(hsv_masked)/255 <= np.sum(img_bound)/255 *0.0005):\n",
    "                        # tends to become darker\n",
    "                        for rgb_set in range(2, len(color_space[legend]), 2):\n",
    "                            color_space[legend][rgb_set] = color_space[legend][rgb_set] -15\n",
    "                            color_space[legend][rgb_set+1] = color_space[legend][rgb_set+1] +5\n",
    "                        #print(color_space[legend][2], color_space[legend][3])\n",
    "                        \n",
    "                        rgb_ms_masked = cv2.inRange(rgb_ms, color_space[legend][2], color_space[legend][3])\n",
    "                        rgb_rb_masked = cv2.inRange(rgb_rb, color_space[legend][2], color_space[legend][3])\n",
    "                        rgb_masked = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "\n",
    "                        img_masked = cv2.bitwise_or(hsv_masked, rgb_masked)\n",
    "\n",
    "                    while poly_counter > 3 and (np.sum(rgb_masked)/255 <= np.sum(img_bound)/255 *0.001):\n",
    "                        # dilation if needed\n",
    "                        for rgb_set in range(2, len(color_space[legend]), 2):\n",
    "                            color_space[legend][rgb_set] = color_space[legend][rgb_set] -1\n",
    "                            color_space[legend][rgb_set+1] = color_space[legend][rgb_set+1] +1\n",
    "                        #print(color_space[legend][2], color_space[legend][3])\n",
    "\n",
    "                        rgb_ms_masked = cv2.inRange(rgb_ms, color_space[legend][2], color_space[legend][3])\n",
    "                        rgb_rb_masked = cv2.inRange(rgb_rb, color_space[legend][2], color_space[legend][3])\n",
    "                        rgb_masked = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "\n",
    "                        img_masked = cv2.bitwise_or(hsv_masked, rgb_masked)\n",
    "\n",
    "                    if (np.sum(rgb_masked)/255 <= np.sum(img_bound)/255 *0.1):\n",
    "                        for rgb_set in range(len(color_space[legend])-2, len(color_space[legend]), 2):\n",
    "                            color_space[legend][rgb_set] = color_space[legend][rgb_set] -15\n",
    "                            color_space[legend][rgb_set+1] = color_space[legend][rgb_set+1] +15\n",
    "                    \n",
    "                    if non_white_background == True:\n",
    "                        if (np.sum(rgb_masked)/255 <= np.sum(img_bound)/255 *0.8):\n",
    "                            img_masked = cv2.bitwise_and(hsv_masked, hsv_masked)\n",
    "                            \n",
    "                if print_intermediate_image == True:\n",
    "                    out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v1_hsv.png'\n",
    "                    cv2.imwrite(out_file_path0, hsv_masked)\n",
    "                    out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v1_rgb.png'\n",
    "                    cv2.imwrite(out_file_path0, rgb_masked)\n",
    "                    out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v2.png'\n",
    "                    cv2.imwrite(out_file_path0, img_masked)\n",
    "                \n",
    "                return legend, img_masked, color_space[legend]\n",
    "            \n",
    "            \n",
    "            # multiprocessing_step2\n",
    "            with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                multiprocessing_results = [pool.apply_async(extraction_step2, (this_poly,)) for this_poly in range(0, poly_counter)]\n",
    "\n",
    "                for this_poly in multiprocessing_results:\n",
    "                    legend, img_masked, this_updated_color_space = this_poly.get()\n",
    "                    # add masked result into private ans_category\n",
    "                    ans_category[legend] = np.copy(img_masked)\n",
    "                    # add mophological result into global ans_category\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                    img_masked_morphology = cv2.morphologyEx(img_masked, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                    img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                    ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "                    \n",
    "                    color_space[legend] = np.copy(this_updated_color_space)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('processing _v0 >>> _v2 (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "        print('time check _v2:', datetime.now()-runningtime_start)\n",
    "        running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "        \n",
    "        \n",
    "        if split_multiprocessing == True and poly_counter > 150: # split legends into multiple parts, multiprocessing for part of legends at a time => recommended if 'more than [around 150] legends in a map'\n",
    "            for_each_loop = for_each_loop_global\n",
    "            looping_times = math.ceil(poly_counter/for_each_loop)\n",
    "        else: # = direct multiprocessing for all legends at a time => recommended if runnable\n",
    "            looping_times = 1\n",
    "            for_each_loop = poly_counter\n",
    "        \n",
    "        for looping in range(0, looping_times):\n",
    "            range_min = 0 + for_each_loop*looping\n",
    "            range_max = min(for_each_loop + for_each_loop*looping, poly_counter)\n",
    "            print('looping... (round: '+str(looping+1)+'/'+str(looping_times)+')... (legend: '+str(range_min)+'-'+str(range_max)+' /'+str(poly_counter)+')')\n",
    "            \n",
    "\n",
    "            for iteration_relaxing in range(0, 4):\n",
    "                global_solution = np.copy(ans_category[poly_counter])\n",
    "                global_solution[global_solution > 0] = 0\n",
    "                global_solution_empty = 255 - global_solution\n",
    "                global_solution_empty = cv2.bitwise_and(global_solution_empty, img_bound)\n",
    "                ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                # multiprocessing_step3\n",
    "                def extraction_step3(legend):\n",
    "                    # fetch current result for this legend\n",
    "                    this_current_result = np.copy(ans_category[legend])\n",
    "\n",
    "                    # create a mask to only preserve current legend color in the basemap\n",
    "                    rgb_ms_masked = cv2.inRange(rgb_ms, color_space[legend][4 + iteration_relaxing*2], color_space[legend][5 + iteration_relaxing*2])\n",
    "                    rgb_rb_masked = cv2.inRange(rgb_rb, color_space[legend][4 + iteration_relaxing*2], color_space[legend][5 + iteration_relaxing*2])\n",
    "                    rgb_masked = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "                    rgb_masked = rgb_masked.astype('uint8')\n",
    "\n",
    "                    # remove moisy white pixels before buffer\n",
    "                    kernel_before_blur = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                    opening_before_blur = cv2.morphologyEx(this_current_result, cv2.MORPH_OPEN, kernel_before_blur, iterations=1)\n",
    "\n",
    "                    # smooth the image\n",
    "                    blur_radius = 1.0\n",
    "                    threshold_blur = 0\n",
    "                    gaussian_buffer = ndimage.gaussian_filter(opening_before_blur, blur_radius)\n",
    "                    gaussian_buffer[gaussian_buffer > threshold_blur] = 255\n",
    "\n",
    "                    current_empty = 255 - this_current_result\n",
    "                    current_relaxing = cv2.bitwise_and(current_empty, gaussian_buffer)\n",
    "\n",
    "                    relaxing_mask = cv2.bitwise_or(rgb_masked, img_crop_black)\n",
    "                    relaxing_mask = cv2.bitwise_or(relaxing_mask, img_crop_gray)\n",
    "\n",
    "                    relaxing_mask = cv2.bitwise_and(relaxing_mask, global_solution_empty)\n",
    "                    relaxing_mask = relaxing_mask.astype('uint8')\n",
    "                    temp_relax = cv2.bitwise_and(current_relaxing, current_relaxing, mask=relaxing_mask)\n",
    "\n",
    "                    this_next_result = cv2.bitwise_or(this_current_result, temp_relax)\n",
    "\n",
    "                    if iteration_relaxing == 3:\n",
    "                        if print_intermediate_image == True:\n",
    "                            out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v3.png'\n",
    "                            cv2.imwrite(out_file_path0, ans_category[legend])\n",
    "                    #print('v3_ ', iteration_relaxing, legend)\n",
    "\n",
    "                    return legend, this_next_result\n",
    "\n",
    "                # multiprocessing_step3\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    multiprocessing_results = [pool.apply_async(extraction_step3, (this_poly,)) for this_poly in range(range_min, range_max)]\n",
    "\n",
    "                    for this_poly in multiprocessing_results:\n",
    "                        legend, this_next_result = this_poly.get()\n",
    "                        # add masked result into private ans_category\n",
    "                        ans_category[legend] = np.copy(this_next_result)\n",
    "                        # add mophological result into global ans_category\n",
    "                        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        img_masked_morphology = cv2.morphologyEx(this_next_result, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                        img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                        ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "\n",
    "                \n",
    "                print('processing _v2 >>> _v3 (iteration '+str(iteration_relaxing+1)+'/4)... (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "            #for legend in range(0, poly_counter):\n",
    "                #out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v3.png'\n",
    "                #cv2.imwrite(out_file_path0, ans_category[legend])\n",
    "\n",
    "            print('time check _v3:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "            img_crop_black_and_gray = cv2.bitwise_or(img_crop_black, img_crop_gray)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # keep record of updated region\n",
    "            #updated_region = np.zeros(poly_counter)\n",
    "            updated_region = []\n",
    "            updated_for_relaxing = np.ones((ans_category[poly_counter].shape[0],ans_category[poly_counter].shape[1]),dtype=np.uint8)*255\n",
    "\n",
    "            # fill ip white pixel (remove noisy black pixel)\n",
    "            for iteration in range(0, 1):\n",
    "                global_solution = np.copy(ans_category[poly_counter])\n",
    "                global_solution_temp = np.copy(ans_category[poly_counter])\n",
    "                global_solution_temp[global_solution_temp > 0] = 0\n",
    "                global_solution_empty = 255 - global_solution_temp\n",
    "                global_solution_empty = cv2.bitwise_and(global_solution_empty, img_bound)\n",
    "                ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                #updated_region = []\n",
    "                next_updated_region = []\n",
    "\n",
    "\n",
    "                def extraction_step4(legend):\n",
    "                    # fetch current result for this legend\n",
    "                    this_current_result = np.copy(ans_category[legend])\n",
    "\n",
    "                    if iteration == 0:\n",
    "                        updated_for_relaxing = np.ones((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)*255\n",
    "                        # remove moisy white pixels before buffer\n",
    "                        kernel_before_blur = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        opening_before_blur = cv2.morphologyEx(this_current_result, cv2.MORPH_OPEN, kernel_before_blur, iterations=1)\n",
    "                    else:\n",
    "                        #updated_for_relaxing = np.copy(updated_region[legend])\n",
    "                        #opening_before_blur = np.copy(updated_for_relaxing)\n",
    "                        updated_for_relaxing = np.ones((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)*255\n",
    "                        # remove moisy white pixels before buffer\n",
    "                        kernel_before_blur = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        opening_before_blur = cv2.morphologyEx(this_current_result, cv2.MORPH_OPEN, kernel_before_blur, iterations=1)\n",
    "\n",
    "                        #print(np.sum(updated_for_relaxing))\n",
    "                        if np.sum(updated_for_relaxing) == 0:\n",
    "                            return legend, this_current_result, updated_for_relaxing\n",
    "                        masked_update = cv2.bitwise_and(rgb_rb, rgb_rb, mask=updated_for_relaxing)\n",
    "\n",
    "                        color_dynamic_placeholder_0 = []\n",
    "                        color_dynamic_placeholder_1 = []\n",
    "                        for dimension in range(0, 3):\n",
    "                            masked_update_np = np.copy(masked_update[:,:,dimension]).astype(float)\n",
    "                            masked_update_np[masked_update_np==0] = np.nan\n",
    "\n",
    "                            color_dynamic_placeholder_0.append(int(np.nanquantile(masked_update_np,.25)))\n",
    "                            color_dynamic_placeholder_1.append(int(np.nanquantile(masked_update_np,.75)))\n",
    "\n",
    "\n",
    "                    # smooth the image\n",
    "                    blur_radius = 5.0 # 5.0\n",
    "                    threshold_blur = 255*0.33 # *0.33\n",
    "                    gaussian_buffer = ndimage.gaussian_filter(opening_before_blur, blur_radius)\n",
    "                    gaussian_buffer[gaussian_buffer > threshold_blur] = 255\n",
    "                    gaussian_buffer[gaussian_buffer <= threshold_blur] = 0\n",
    "\n",
    "                    current_empty = 255 - this_current_result\n",
    "                    current_relaxing = cv2.bitwise_and(current_empty, gaussian_buffer)\n",
    "                    #current_relaxing = cv2.bitwise_and(current_relaxing, updated_for_relaxing)  # shall not bitwise_and here <= already considered from gaussian_buffer <= opening_before_blur\n",
    "\n",
    "                    current_relaxing = cv2. bitwise_and(current_relaxing, global_solution_empty)\n",
    "                    #current_relaxing_arg = np.argwhere(current_relaxing == 255)\n",
    "\n",
    "                    updated_for_relaxing = np.zeros((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)\n",
    "\n",
    "\n",
    "                    if iteration == 0:\n",
    "                        rgb_ms_masked = cv2.inRange(rgb_ms, color_space[legend][4 + 3*2], color_space[legend][5 + 3*2])\n",
    "                        rgb_rb_masked = cv2.inRange(rgb_rb, color_space[legend][4 + 3*2], color_space[legend][5 + 3*2])\n",
    "\n",
    "                        rgb_masked_dynamic = cv2.bitwise_or(rgb_ms_masked, rgb_rb_masked)\n",
    "                        rgb_masked_dynamic = rgb_masked_dynamic.astype('uint8')\n",
    "                    elif iteration >= 1 and iteration <= 1:\n",
    "                    #else:\n",
    "                        rgb_dynamic_lower_box = np.array([color_dynamic_placeholder_0[0], color_dynamic_placeholder_0[1], color_dynamic_placeholder_0[2]])\n",
    "                        rgb_dynamic_upper_box = np.array([color_dynamic_placeholder_1[0], color_dynamic_placeholder_1[1], color_dynamic_placeholder_1[2]])\n",
    "\n",
    "                        # create a mask to only preserve current legend color in the basemap\n",
    "                        rgb_masked_dynamic = cv2.inRange(rgb_rb, rgb_dynamic_lower_box, rgb_dynamic_upper_box)\n",
    "                        rgb_masked_dynamic = rgb_masked_dynamic.astype('uint8')\n",
    "\n",
    "\n",
    "                    masking_targeted_color = cv2.bitwise_and(current_relaxing, rgb_masked_dynamic)\n",
    "                    masking_black_and_gray = cv2.bitwise_and(current_relaxing, img_crop_black_and_gray)\n",
    "                    #masking_self = cv2.bitwise_and(current_relaxing, this_current_result)\n",
    "\n",
    "                    if iteration == 0:\n",
    "                        this_next_result = cv2.bitwise_or(this_current_result, masking_targeted_color)\n",
    "                        this_next_result = cv2.bitwise_or(this_next_result, masking_black_and_gray)\n",
    "                    else:\n",
    "                        this_next_result = cv2.bitwise_or(this_current_result, masking_targeted_color)\n",
    "                        this_next_result = cv2.bitwise_or(this_next_result, masking_black_and_gray)\n",
    "\n",
    "                    updated_for_relaxing = cv2.subtract(this_next_result, this_current_result)\n",
    "                    \n",
    "                    if print_intermediate_image == True:\n",
    "                        out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v4.png'\n",
    "                        cv2.imwrite(out_file_path0, this_next_result)\n",
    "\n",
    "                    return legend, this_next_result, updated_for_relaxing\n",
    "\n",
    "\n",
    "                # multiprocessing_step4\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    multiprocessing_results = [pool.apply_async(extraction_step4, (this_poly,)) for this_poly in range(range_min, range_max)]\n",
    "\n",
    "                    for this_poly in multiprocessing_results:\n",
    "                        legend, this_next_result, updated_for_relaxing = this_poly.get()\n",
    "                        # add masked result into private ans_category\n",
    "                        ans_category[legend] = np.copy(this_next_result)\n",
    "                        # add mophological result into global ans_category\n",
    "                        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        img_masked_morphology = cv2.morphologyEx(this_next_result, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                        img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                        ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "\n",
    "                        next_updated_region.append(np.copy(updated_for_relaxing))\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                updated_region = np.array(np.copy(next_updated_region))\n",
    "                print('processing _v3 >>> _v4 (iteration '+str(iteration+1)+'/1)... (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "            #for legend in range(0, poly_counter):\n",
    "                #out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v4.png'\n",
    "                #cv2.imwrite(out_file_path0, ans_category[legend])\n",
    "            ans_category_temp = np.copy(ans_category)\n",
    "\n",
    "            print('time check _v4:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            conv_kernel_set = []\n",
    "            conv_kernel_threshold0 = [1.0, 0.75, 0.75, 0.5, 0.5, 0.5, 0.5]#, 0.5, 0.5, 0.5]\n",
    "            conv_kernel_threshold = []\n",
    "\n",
    "            conv_kernel_0 = np.ones((3,3),dtype=np.uint8)\n",
    "            conv_kernel_0[1,1] = 0\n",
    "            conv_kernel_1 = np.ones((5,5),dtype=np.uint8)\n",
    "            conv_kernel_1[2,2] = 0\n",
    "            conv_kernel_2 = np.ones((7,7),dtype=np.uint8)\n",
    "            conv_kernel_2[2:5,2:5] = 0\n",
    "            conv_kernel_3 = np.ones((9,9),dtype=np.uint8)\n",
    "            conv_kernel_3[3:6,3:6] = 0\n",
    "            conv_kernel_4 = np.ones((11,11),dtype=np.uint8)\n",
    "            conv_kernel_4[3:8,3:8] = 0\n",
    "            conv_kernel_5 = np.ones((13,13),dtype=np.uint8)\n",
    "            conv_kernel_5[4:9,4:9] = 0\n",
    "            conv_kernel_6 = np.ones((15,15),dtype=np.uint8)\n",
    "            conv_kernel_6[4:11,4:11] = 0\n",
    "\n",
    "            conv_kernel_set.append(conv_kernel_0)\n",
    "            conv_kernel_set.append(conv_kernel_1)\n",
    "            conv_kernel_set.append(conv_kernel_2)\n",
    "            conv_kernel_set.append(conv_kernel_3)\n",
    "            conv_kernel_set.append(conv_kernel_4)\n",
    "            conv_kernel_set.append(conv_kernel_5)\n",
    "            conv_kernel_set.append(conv_kernel_6)\n",
    "\n",
    "            for conv_set in range(0, len(conv_kernel_set)):\n",
    "                conv_kernel_threshold.append(np.sum(conv_kernel_set[conv_set])*conv_kernel_threshold0[conv_set])\n",
    "\n",
    "\n",
    "\n",
    "            boundingRange = 3\n",
    "            masking0 = generate_mask(boundingRange)\n",
    "            masking = np.copy(masking0)\n",
    "            masking = masking.astype(float)\n",
    "\n",
    "            for direction in range(0, 8):\n",
    "                #print((masking[direction]==1.0).sum())\n",
    "                region_sum = (masking[direction]==1.0).sum()\n",
    "                for i, j in np.argwhere(masking[direction]==1.0):\n",
    "                    masking[direction][i][j] = (1.0/region_sum)\n",
    "\n",
    "\n",
    "            # keep record of updated region\n",
    "            #updated_region = np.zeros(poly_counter)\n",
    "            updated_region = []\n",
    "            updated_for_relaxing = np.ones((ans_category[poly_counter].shape[0],ans_category[poly_counter].shape[1]),dtype=np.uint8)*255\n",
    "\n",
    "            # fill ip white pixel (remove noisy black pixel)\n",
    "            for iteration in range(0, 1):\n",
    "                global_solution = np.copy(ans_category[poly_counter])\n",
    "                global_solution_temp = np.copy(ans_category[poly_counter])\n",
    "                global_solution_temp[global_solution_temp > 0] = 0\n",
    "                global_solution_empty = 255 - global_solution_temp\n",
    "                global_solution_empty = cv2.bitwise_and(global_solution_empty, img_bound)\n",
    "                ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                #updated_region = []\n",
    "                next_updated_region = []\n",
    "\n",
    "\n",
    "                def extraction_step5(legend):\n",
    "                    # fetch current result for this legend\n",
    "                    this_current_result = np.copy(ans_category[legend])\n",
    "\n",
    "                    if iteration == 0:\n",
    "                        updated_for_relaxing = np.ones((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)*255\n",
    "                        # remove moisy white pixels before buffer\n",
    "                        kernel_before_blur = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        opening_before_blur = cv2.morphologyEx(this_current_result, cv2.MORPH_OPEN, kernel_before_blur, iterations=1)\n",
    "                    else:\n",
    "                        updated_for_relaxing = np.ones((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)*255\n",
    "                        # remove moisy white pixels before buffer\n",
    "                        kernel_before_blur = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        opening_before_blur = cv2.morphologyEx(this_current_result, cv2.MORPH_OPEN, kernel_before_blur, iterations=1)\n",
    "\n",
    "                        print(np.sum(updated_for_relaxing))\n",
    "\n",
    "                        if np.sum(updated_for_relaxing) == 0:\n",
    "                            return legend, this_current_result, updated_for_relaxing\n",
    "                        \n",
    "\n",
    "                        masked_update = cv2.bitwise_and(rgb_rb, rgb_rb, mask=updated_for_relaxing)\n",
    "\n",
    "                        color_dynamic_placeholder_0 = []\n",
    "                        color_dynamic_placeholder_1 = []\n",
    "                        for dimension in range(0, 3):\n",
    "                            masked_update_np = np.copy(masked_update[:,:,dimension]).astype(float)\n",
    "                            masked_update_np[masked_update_np==0] = np.nan\n",
    "\n",
    "                            color_dynamic_placeholder_0.append(int(np.nanquantile(masked_update_np,.01)))\n",
    "                            color_dynamic_placeholder_1.append(min(int(np.nanquantile(masked_update_np,.99)), 254))\n",
    "                        print(color_dynamic_placeholder_0, color_dynamic_placeholder_1)\n",
    "\n",
    "\n",
    "                    # smooth the image\n",
    "                    if iteration == 0:\n",
    "                        threshold_blur = 255*0.0\n",
    "                    else:\n",
    "                        threshold_blur = 255*0.0\n",
    "                    blur_radius = 5.0\n",
    "                    gaussian_buffer = ndimage.gaussian_filter(opening_before_blur, blur_radius)\n",
    "                    gaussian_buffer[gaussian_buffer > threshold_blur] = 255\n",
    "                    gaussian_buffer[gaussian_buffer <= threshold_blur] = 0\n",
    "\n",
    "                    current_empty = 255 - this_current_result\n",
    "                    current_relaxing = cv2.bitwise_and(current_empty, gaussian_buffer)\n",
    "                    #current_relaxing = cv2.bitwise_and(current_relaxing, updated_for_relaxing) # shall not bitwise_and here <= already considered from gaussian_buffer <= opening_before_blur\n",
    "\n",
    "                    current_relaxing = cv2. bitwise_and(current_relaxing, global_solution_empty)\n",
    "                    #current_relaxing_arg = np.argwhere(current_relaxing == 255)\n",
    "\n",
    "                    updated_for_relaxing = np.zeros((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "                    this_current_result_scale = np.copy(this_current_result)\n",
    "                    this_current_result_scale[this_current_result_scale > 0] = 1\n",
    "                    this_current_result_scale_v0 = np.copy(this_current_result_scale)\n",
    "                    if iteration > 0:\n",
    "                        rgb_dynamic_lower_box = np.array([color_dynamic_placeholder_0[0], color_dynamic_placeholder_0[1], color_dynamic_placeholder_0[2]])\n",
    "                        rgb_dynamic_upper_box = np.array([color_dynamic_placeholder_1[0], color_dynamic_placeholder_1[1], color_dynamic_placeholder_1[2]])\n",
    "                        print(rgb_dynamic_lower_box, rgb_dynamic_upper_box)\n",
    "\n",
    "                        # create a mask to only preserve current legend color in the basemap\n",
    "                        rgb_masked_dynamic = cv2.inRange(rgb_rb, rgb_dynamic_lower_box, rgb_dynamic_upper_box)\n",
    "                        rgb_masked_dynamic[rgb_masked_dynamic > 0] = 1\n",
    "                        rgb_masked_dynamic = rgb_masked_dynamic.astype('uint8')\n",
    "\n",
    "                        #masking_targeted_color = cv2.bitwise_and(current_relaxing, rgb_masked_dynamic)\n",
    "                        #masking_black_and_gray = cv2.bitwise_and(current_relaxing, img_crop_black_and_gray)\n",
    "                        #masking_self = cv2.bitwise_and(current_relaxing, this_current_result)\n",
    "\n",
    "                        conv_masking_targeted = np.zeros((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)\n",
    "                        for conv_set in range(0, len(conv_kernel_set)):\n",
    "                            conv_mask_self = cv2.filter2D(src=this_current_result_scale, ddepth=-1, kernel=conv_kernel_set[conv_set])\n",
    "                            conv_mask_relax = cv2.filter2D(src=rgb_masked_dynamic, ddepth=-1, kernel=conv_kernel_set[conv_set])\n",
    "                            conv_mask_bg = cv2.filter2D(src=img_crop_black_and_gray, ddepth=-1, kernel=conv_kernel_set[conv_set])\n",
    "\n",
    "                            conv_out_placeholder = np.copy(this_current_result_scale)\n",
    "                            conv_out_placeholder[np.logical_and(conv_mask_self>=conv_kernel_threshold[conv_set], conv_mask_relax>=conv_kernel_threshold[conv_set], this_current_result_scale_v0==0)] = 1\n",
    "                            conv_out_placeholder[conv_out_placeholder > 0] = 255\n",
    "                            conv_masking_targeted = cv2.bitwise_or(conv_masking_targeted, conv_out_placeholder)\n",
    "\n",
    "\n",
    "                        masking_targeted_conv = cv2.bitwise_and(current_relaxing, conv_masking_targeted)\n",
    "\n",
    "\n",
    "                        updated_from_filtering = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                        updated_record = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                        updated_record[0:this_current_result_scale.shape[0], 0:this_current_result_scale.shape[1]] = 3\n",
    "                        tabo_list = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "\n",
    "\n",
    "                        for this_direction in range(0, 8+2):\n",
    "                            direction = this_direction\n",
    "                            if this_direction >= 8:\n",
    "                                direction = this_direction - 8\n",
    "\n",
    "                            dir_filtered = cv2.filter2D(src=this_current_result_scale, ddepth=-1, kernel=masking[direction]) # img_bw_for_filter\n",
    "                            dir_filtered[dir_filtered <= 255*0.5] = 0\n",
    "                            dir_filtered[dir_filtered > 255*0.5] = 255 / 8.0\n",
    "\n",
    "                            #directional_filter.append(dir_filtered)\n",
    "                            if this_direction < 8:\n",
    "                                updated_from_filtering = cv2.add(updated_from_filtering, dir_filtered)\n",
    "\n",
    "                            dir_record = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                            dir_record[dir_filtered > 0.0] = 1\n",
    "                            updated_record = cv2.add(updated_record, dir_record)\n",
    "                            updated_record = cv2.subtract(updated_record, np.ones((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8))\n",
    "                            #print('unique value(s):', np.unique(updated_record))\n",
    "\n",
    "                            if this_direction >= 3:\n",
    "                                updated_tabo = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                                updated_tabo[updated_record <= 0] = 1\n",
    "                                tabo_list = cv2.bitwise_or(tabo_list, updated_tabo)\n",
    "                        \n",
    "                        tabo_list[tabo_list > 0] = 255\n",
    "                        tabo_list = tabo_list - 255\n",
    "\n",
    "                        updated_with_checking = np.copy(updated_from_filtering)\n",
    "                        updated_with_checking[updated_from_filtering < 255*3/8] = 0\n",
    "                        updated_with_checking[updated_from_filtering >= 255*3/8] = 255\n",
    "                        updated_with_checking[updated_from_filtering > 255*5/8] = 0\n",
    "                        updated_with_checking = cv2.bitwise_and(updated_with_checking, tabo_list)\n",
    "\n",
    "                        updated_from_filtering[updated_from_filtering <= 255*5/8] = 0\n",
    "                        updated_from_filtering[updated_from_filtering > 255*5/8] = 255\n",
    "\n",
    "\n",
    "                        this_next_result = cv2.bitwise_or(this_current_result, masking_targeted_conv)\n",
    "                        this_next_result = cv2.bitwise_or(this_next_result, updated_from_filtering)\n",
    "                    if iteration == 0:\n",
    "                        conv_masking_targeted = np.zeros((this_current_result.shape[0],this_current_result.shape[1]),dtype=np.uint8)\n",
    "                        for conv_set in range(0, len(conv_kernel_set)):\n",
    "                            conv_mask = cv2.filter2D(src=this_current_result_scale, ddepth=-1, kernel=conv_kernel_set[conv_set])\n",
    "                            conv_out_placeholder = np.copy(this_current_result_scale)\n",
    "                            conv_out_placeholder[np.logical_and(conv_mask>=conv_kernel_threshold[conv_set], this_current_result_scale_v0==0)] = 1\n",
    "                            conv_out_placeholder[conv_out_placeholder > 0] = 255\n",
    "                            conv_masking_targeted = cv2.bitwise_or(conv_masking_targeted, conv_out_placeholder)\n",
    "\n",
    "                        masking_targeted_conv = cv2.bitwise_and(current_relaxing, conv_masking_targeted)\n",
    "\n",
    "\n",
    "                        updated_from_filtering = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                        updated_record = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                        updated_record[0:this_current_result_scale.shape[0], 0:this_current_result_scale.shape[1]] = 3\n",
    "                        tabo_list = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "\n",
    "\n",
    "                        for this_direction in range(0, 8+2):\n",
    "                            direction = this_direction\n",
    "                            if this_direction >= 8:\n",
    "                                direction = this_direction - 8\n",
    "\n",
    "                            dir_filtered = cv2.filter2D(src=this_current_result_scale, ddepth=-1, kernel=masking[direction]) # img_bw_for_filter\n",
    "                            #print(np.unique(dir_filtered))\n",
    "                            dir_filtered[dir_filtered <= 255*0.5] = 0\n",
    "                            dir_filtered[dir_filtered > 255*0.5] = 255 / 8.0\n",
    "\n",
    "                            #directional_filter.append(dir_filtered)\n",
    "                            if this_direction < 8:\n",
    "                                updated_from_filtering = cv2.add(updated_from_filtering, dir_filtered)\n",
    "\n",
    "                            dir_record = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                            dir_record[dir_filtered > 0.0] = 1\n",
    "                            updated_record = cv2.add(updated_record, dir_record)\n",
    "                            updated_record = cv2.subtract(updated_record, np.ones((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8))\n",
    "                            #print('unique value(s):', np.unique(updated_record))\n",
    "\n",
    "                            if this_direction >= 3:\n",
    "                                updated_tabo = np.zeros((this_current_result_scale.shape[0],this_current_result_scale.shape[1]),dtype=np.uint8)\n",
    "                                updated_tabo[updated_record <= 0] = 1\n",
    "                                tabo_list = cv2.bitwise_or(tabo_list, updated_tabo)\n",
    "                        \n",
    "                        tabo_list[tabo_list > 0] = 255\n",
    "                        tabo_list = tabo_list - 255\n",
    "\n",
    "                        updated_with_checking = np.copy(updated_from_filtering)\n",
    "                        updated_with_checking[updated_from_filtering < 255*3/8] = 0\n",
    "                        updated_with_checking[updated_from_filtering >= 255*3/8] = 255\n",
    "                        updated_with_checking[updated_from_filtering > 255*5/8] = 0\n",
    "                        updated_with_checking = cv2.bitwise_and(updated_with_checking, tabo_list)\n",
    "\n",
    "                        updated_from_filtering[updated_from_filtering <= 255*5/8] = 0\n",
    "                        updated_from_filtering[updated_from_filtering > 255*5/8] = 255\n",
    "\n",
    "\n",
    "                        this_next_result = cv2.bitwise_or(this_current_result, masking_targeted_conv)\n",
    "                        this_next_result = cv2.bitwise_or(this_next_result, updated_from_filtering)\n",
    "\n",
    "\n",
    "                    updated_for_relaxing = cv2.subtract(this_next_result, this_current_result)\n",
    "                    \n",
    "                    if print_intermediate_image == True:\n",
    "                        out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v5.png'\n",
    "                        cv2.imwrite(out_file_path0, this_next_result)\n",
    "\n",
    "                    return legend, this_next_result, updated_for_relaxing\n",
    "\n",
    "\n",
    "                # multiprocessing_step5\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    multiprocessing_results = [pool.apply_async(extraction_step5, (this_poly,)) for this_poly in range(range_min, range_max)]\n",
    "\n",
    "                    for this_poly in multiprocessing_results:\n",
    "                        legend, this_next_result, updated_for_relaxing = this_poly.get()\n",
    "                        # add masked result into private ans_category\n",
    "                        ans_category[legend] = np.copy(this_next_result)\n",
    "                        # add mophological result into global ans_category\n",
    "                        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        img_masked_morphology = cv2.morphologyEx(this_next_result, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                        img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                        ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "\n",
    "                        next_updated_region.append(np.copy(updated_for_relaxing))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                updated_region = np.array(np.copy(next_updated_region))\n",
    "                print('processing _v4 >>> _v5 (iteration '+str(iteration+1)+'/1)... (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "            #ans_category_updated = []\n",
    "            #for legend in range(0, poly_counter):\n",
    "                #out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v5.png'\n",
    "                #cv2.imwrite(out_file_path0, ans_category[legend])\n",
    "\n",
    "                #ans_category_updated_placeholder = cv2.subtract(ans_category[legend], ans_category_temp[legend])\n",
    "                #ans_category_updated.append(ans_category_updated_placeholder)\n",
    "\n",
    "            #ans_category_temp = np.copy(ans_category)\n",
    "            print('time check _v5:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if poly_counter >= 5 and poly_counter <= 150:\n",
    "                print('proceed to text detection...')\n",
    "\n",
    "                img_backgroun_v0 = np.copy(img_rb)\n",
    "\n",
    "                lower_black_text = np.array([0,0,0])\n",
    "                upper_black_text = np.array([70,70,70])\n",
    "                mask_box_text0 = cv2.inRange(img_backgroun_v0, lower_black_text, upper_black_text)\n",
    "                res_box_text1 = cv2.bitwise_and(img_bound, img_bound, mask=mask_box_text0)\n",
    "                threshold_text = cv2.medianBlur(res_box_text1,3)\n",
    "\n",
    "                global_hsv_space = np.zeros((3, 400), dtype='uint8')\n",
    "                local_hsv_space = np.zeros((poly_counter, 3, 400), dtype='uint8')\n",
    "                #hsv_color_space = np.zeros((poly_counter, 2, 3), dtype='uint8')\n",
    "                hsv_color_space = []\n",
    "\n",
    "                for legend in range(range_min, range_max): ###\n",
    "                    color_space_holder = []\n",
    "                    color_space_holder.append(color_space[legend][0])\n",
    "                    color_space_holder.append(color_space[legend][1])\n",
    "\n",
    "                    this_hsv_color_space = np.copy(color_space_holder)\n",
    "                    #hsv_color_space[legend] = np.copy(color_space_holder)\n",
    "                    hsv_color_space.append(color_space_holder)\n",
    "                    #print(legend_name[legend], color_space_holder, hsv_color_space[legend][1], this_hsv_color_space)\n",
    "\n",
    "                    global_hsv_space[0][max(this_hsv_color_space[0][0]-1, 0): 1+this_hsv_color_space[1][0]+1] += 1 # h space\n",
    "                    global_hsv_space[1][max(this_hsv_color_space[0][1]-15, 0): 1+this_hsv_color_space[1][1]+15] += 1 # s space\n",
    "                    global_hsv_space[2][max(this_hsv_color_space[0][2]-15, 0): 1+this_hsv_color_space[1][2]+15] += 1 # v space\n",
    "                    local_hsv_space[legend][0][max(this_hsv_color_space[0][0]-1, 0): 1+this_hsv_color_space[1][0]+1] = 1 # h space\n",
    "                    local_hsv_space[legend][1][max(this_hsv_color_space[0][1]-15, 0): 1+this_hsv_color_space[1][1]+15] = 1 # s space\n",
    "                    local_hsv_space[legend][2][max(this_hsv_color_space[0][2]-15, 0): 1+this_hsv_color_space[1][2]+15] = 1 # v space\n",
    "\n",
    "                #print('legend loaded...')\n",
    "\n",
    "                print('time check _text_v0:', datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                def pre_v6_update(legend):\n",
    "                    ### v6\n",
    "                    # remove noisy white pixel\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                    opening = cv2.morphologyEx(ans_category[legend], cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                    return_image =cv2.threshold(opening, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "                    if np.unique(ans_category[legend]).shape[0] != 2:\n",
    "                        print('extract nothing...')\n",
    "                        return_image = np.copy(img_bound)\n",
    "\n",
    "                    return legend, return_image\n",
    "\n",
    "                # multiprocessing\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    multiprocessing_results = [pool.apply_async(pre_v6_update, (this_poly,)) for this_poly in range(range_min, range_max)]\n",
    "\n",
    "                    for this_poly in multiprocessing_results:\n",
    "                        legend, return_image = this_poly.get()\n",
    "                        ans_category[legend] = np.copy(return_image)\n",
    "                print('v6 updated...')\n",
    "\n",
    "\n",
    "\n",
    "                comparison_needed = []\n",
    "                comparison_target = np.empty(poly_counter, dtype=object)\n",
    "\n",
    "\n",
    "                #for legend in range(0, poly_counter):\n",
    "                def specify_overlap_legend(legend):\n",
    "                    has_similar_legend = False\n",
    "                    overlapping_issue = False\n",
    "                    similar_legend = []\n",
    "\n",
    "\n",
    "                    if True:\n",
    "                        for counter_legend in range(range_min, range_max):\n",
    "                            if counter_legend == legend:\n",
    "                                continue\n",
    "\n",
    "                            # First, check huge simple overlapping\n",
    "                            ## a loose restriction for color space\n",
    "                            if np.sum(local_hsv_space[counter_legend][0][max(hsv_color_space[legend][0][0]-10, 0): 1+hsv_color_space[legend][1][0]+10]) > 0:\n",
    "                                if np.sum(local_hsv_space[counter_legend][1][max(hsv_color_space[legend][0][1]-25, 0): 1+hsv_color_space[legend][1][1]+25]) > 0:\n",
    "                                    if np.sum(local_hsv_space[counter_legend][2][max(hsv_color_space[legend][0][2]-25, 0): 1+hsv_color_space[legend][1][2]+25]) > 0:\n",
    "                                        if np.mean(ans_category[legend]) > 0 and np.mean(ans_category[counter_legend]) > 0:\n",
    "                                            ans_overlap = cv2.bitwise_and(ans_category[legend], ans_category[counter_legend])\n",
    "\n",
    "                                            if (np.mean(ans_overlap) / np.mean(ans_category[legend])) > 0.66 and (np.mean(ans_overlap) / np.mean(ans_category[counter_legend])) > 0.66:\n",
    "                                                # if there are few overlaps in v6 extracted answer, than we don't need text detection\n",
    "                                                #print('we need to compare them')\n",
    "                                                #print('overlapping issue with large area: '+legend_name[legend]+' <-> '+legend_name[counter_legend])\n",
    "                                                similar_legend.append(counter_legend)\n",
    "                                                overlapping_issue = True\n",
    "                                                continue\n",
    "\n",
    "\n",
    "                            # Second, check color overlapping\n",
    "                            ## no need to proceed if there is no overlap in h space for this legend\n",
    "                            if np.mean(global_hsv_space[0][max(hsv_color_space[legend][0][0]-1, 0): 1+hsv_color_space[legend][1][0]+1]) > 1:\n",
    "\n",
    "                                # only compare legends with the same first character\n",
    "                                if legend_name[legend][0] not in legend_name[counter_legend][0]:\n",
    "                                    continue\n",
    "\n",
    "                                combined_hsv_space = local_hsv_space[legend] + local_hsv_space[counter_legend]\n",
    "\n",
    "                                if np.max(combined_hsv_space[0]) > 1 and np.max(combined_hsv_space[1]) > 1 and np.max(combined_hsv_space[2]) > 1:\n",
    "                                    # if there are overlaps in all hsv spaces, than we probably need to proceed to text detection\n",
    "\n",
    "                                    ans_overlap = cv2.bitwise_and(ans_category[legend], ans_category[counter_legend])\n",
    "                                    if np.mean(ans_category[legend]) > 0 and np.mean(ans_category[counter_legend]) > 0:\n",
    "                                        if (np.mean(ans_overlap) / np.mean(ans_category[legend])) > 0.2 and (np.mean(ans_overlap) / np.mean(ans_category[counter_legend])) > 0.2:\n",
    "                                            # if there are few overlaps in v6 extracted answer, than we don't need text detection\n",
    "                                            #print('we need to compare them')\n",
    "                                            #print('overlapping issue with similar color: '+legend_name[legend]+' <-> '+legend_name[counter_legend])\n",
    "                                            similar_legend.append(counter_legend)\n",
    "                                            has_similar_legend = True\n",
    "                    return legend, similar_legend\n",
    "\n",
    "\n",
    "                # multiprocessing\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    multiprocessing_results = [pool.apply_async(specify_overlap_legend, (this_poly,)) for this_poly in range(range_min, range_max)]\n",
    "\n",
    "                    for this_poly in multiprocessing_results:\n",
    "                        legend, similar_legend = this_poly.get()\n",
    "                        comparison_target[legend] = np.copy(similar_legend)\n",
    "                        if len(similar_legend) > 0:\n",
    "                            comparison_needed.append(legend)\n",
    "                print(comparison_target)\n",
    "                print(comparison_needed)\n",
    "\n",
    "                print('time check _text_v1:', datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                def distance_to_depot(x1, y1, x2, y2):\n",
    "                    return math.pow(math.pow(x1-x2, 2)+math.pow(y1-y2, 2), 0.5)\n",
    "\n",
    "\n",
    "                #global_res_probability = np.zeros((poly_counter, threshold_text.shape[0], threshold_text.shape[1]), dtype='uint8')\n",
    "                global_res_probability = np.empty(poly_counter, dtype=object)\n",
    "                global_confidence = np.empty(poly_counter, dtype=object)\n",
    "\n",
    "                def find_legend_in_map(legend):\n",
    "                    # fetch current result for this legend\n",
    "                    this_current_result = np.copy(ans_category[legend])\n",
    "\n",
    "\n",
    "                    img_legend_v0 = cv2.imread(os.path.join('intermediate7(2)', map_name, map_name+'_'+legend_name[legend]+'_poly_legend.tif'))\n",
    "                    img_legend_v1 = img_legend_v0[int(img_legend_v0.shape[0]/8):img_legend_v0.shape[0]-int(img_legend_v0.shape[0]/8), int(img_legend_v0.shape[1]/8):img_legend_v0.shape[1]-int(img_legend_v0.shape[1]/8)]\n",
    "\n",
    "                    lower_black_text = np.array([0,0,0])\n",
    "                    upper_black_text = np.array([70,70,70])\n",
    "                    mask_box_legend = cv2.inRange(img_legend_v1, lower_black_text, upper_black_text)\n",
    "                    mask_box_legend = cv2.medianBlur(mask_box_legend,3)\n",
    "                    #plt.imshow(mask_box_legend)\n",
    "                    #plt.show()\n",
    "\n",
    "                    # threshold_text = processed map with text highlighted\n",
    "                    res = cv2.matchTemplate(threshold_text, mask_box_legend, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "                    #global_res_probability[legend] = np.copy(res) ###\n",
    "\n",
    "                    #threshold = 0.75\n",
    "                    #loc = np.where(res >= threshold)\n",
    "                    #loc_arg = np.argwhere(res >= threshold)\n",
    "                    #print(loc_arg.shape)\n",
    "                    \n",
    "                    \n",
    "                    return legend, res\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                # multiprocessing\n",
    "                list_for_multiprocessing = []\n",
    "                for list_id in range(0, len(comparison_needed)):\n",
    "                    legend = comparison_needed[list_id]\n",
    "                    list_for_multiprocessing.append(legend)\n",
    "                #print(list_for_multiprocessing)\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    multiprocessing_results = [pool.apply_async(find_legend_in_map, (this_poly,)) for this_poly in list_for_multiprocessing]\n",
    "\n",
    "                    for this_poly in multiprocessing_results:\n",
    "                        '''\n",
    "                        legend, res, confidence_placeholder = this_poly.get()\n",
    "                        global_res_probability[legend] = np.copy(res)\n",
    "                        global_confidence[legend] = np.copy(confidence_placeholder)\n",
    "                        '''\n",
    "                        \n",
    "                        legend, res = this_poly.get()\n",
    "                        global_res_probability[legend] = np.copy(res)\n",
    "                        \n",
    "                        threshold = 0.75\n",
    "                        loc = np.where(res >= threshold)\n",
    "                        loc_arg = np.argwhere(res >= threshold)\n",
    "                        while len(loc[0]) == 0 and threshold >= 0:\n",
    "                            threshold = threshold - 0.1\n",
    "                            loc = np.where(res >= threshold)\n",
    "                            loc_arg = np.argwhere(res >= threshold)\n",
    "                        global_confidence[legend] = np.copy(loc_arg)\n",
    "                        \n",
    "\n",
    "                print('time check _text_v2:', datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                def generate_cluster(input_image, blur_radius_initial, blur_radius_step):\n",
    "                    # smooth the image (to remove small objects)\n",
    "                    blur_radius = blur_radius_initial\n",
    "                    threshold_blur = 0\n",
    "                    imgf = ndimage.gaussian_filter(input_image, blur_radius)\n",
    "\n",
    "                    # find connected components\n",
    "                    labeled, nr_objects = ndimage.label(imgf > threshold_blur)\n",
    "\n",
    "                    while nr_objects > 100:\n",
    "                        # smooth the image (to remove small objects)\n",
    "                        blur_radius = blur_radius + blur_radius_step\n",
    "                        threshold_blur = 0\n",
    "                        imgf = ndimage.gaussian_filter(input_image, blur_radius)\n",
    "\n",
    "                        # find connected components\n",
    "                        labeled, nr_objects = ndimage.label(imgf > threshold_blur)\n",
    "\n",
    "\n",
    "                    current_nr_objects = nr_objects\n",
    "                    for object_traverse in range(1, nr_objects):\n",
    "                        # if this object is too large (span from large x-y), split into pieces based on grid\n",
    "                        cluster_object_arg = np.argwhere(labeled == object_traverse)\n",
    "                        #print(cluster_object_arg.min(0), cluster_object_arg.max(0))\n",
    "\n",
    "                        (y_min, x_min), (y_max, x_max) = cluster_object_arg.min(0), cluster_object_arg.max(0) + 1 \n",
    "                        if (y_max-y_min) > 3000 and (x_max-x_min) > 3000:\n",
    "                            #print(y_min,y_max, x_min,x_max)\n",
    "                            this_labeled_object = np.copy(labeled)\n",
    "                            this_labeled_object[this_labeled_object > object_traverse] = 0\n",
    "                            this_labeled_object[this_labeled_object < object_traverse] = 0\n",
    "                            this_labeled_object[this_labeled_object == object_traverse] = current_nr_objects\n",
    "\n",
    "                            # construct a 1000*1000 grid\n",
    "                            min_w = math.floor(y_min/1000)\n",
    "                            max_w = math.floor(y_max/1000)\n",
    "                            min_h = math.floor(x_min/1000)\n",
    "                            max_h = math.floor(x_max/1000)\n",
    "\n",
    "                            #print(min_w, max_w, min_h, max_h)\n",
    "                            this_grid = np.zeros((ans_category[legend].shape[0], ans_category[legend].shape[1]), dtype='uint8')\n",
    "                            for grid_w in range(min_w, max_w+1):\n",
    "                                for grid_h in range(min_h, max_h+1):\n",
    "                                    this_adding = (grid_w-min_w)*(max_h+1-min_h) + grid_h + 1\n",
    "                                    this_grid[grid_w*1000:(grid_w+1)*1000, grid_h*1000:(grid_h+1)*1000] = this_adding\n",
    "\n",
    "                            #updated_labeled = np.copy(labeled)\n",
    "                            grid_count = (max_w-min_w)*(max_h-min_h)\n",
    "                            for local_grid in range(0, grid_count):\n",
    "                                #print(current_nr_objects+local_grid)\n",
    "                                labeled[np.logical_and(labeled==object_traverse, this_grid==local_grid)] = (current_nr_objects+local_grid)\n",
    "\n",
    "                            current_nr_objects = current_nr_objects+grid_count\n",
    "                    nr_objects = current_nr_objects\n",
    "\n",
    "                    return labeled, nr_objects\n",
    "\n",
    "\n",
    "                def update_based_on_text(legend, counter_legend):\n",
    "                    img_ans_v0 = np.copy(ans_category[legend])\n",
    "                    #save_region_temp = cv2.subtract(ans_category[legend], ans_category[counter_legend])\n",
    "                    temp_competitor = 255 - ans_category[counter_legend]\n",
    "                    save_region_temp = cv2.bitwise_and(ans_category[legend], temp_competitor)\n",
    "                    img_ans_v0 = cv2.subtract(img_ans_v0, save_region_temp)\n",
    "\n",
    "                    labeled, nr_objects = generate_cluster(img_ans_v0, 15.0, 5.0)\n",
    "\n",
    "                    depot_checked_polygon = np.zeros((labeled.shape[0],labeled.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                    depot_got = 0\n",
    "                    distance_threshold = 300\n",
    "\n",
    "                    for object_traverse in range(1, nr_objects):\n",
    "                        cluster_object = np.argwhere(labeled == object_traverse)\n",
    "                        if cluster_object.shape[0] == 0:\n",
    "                            continue\n",
    "\n",
    "                        center_x = np.mean(cluster_object, axis=0)[0]\n",
    "                        center_y = np.mean(cluster_object, axis=0)[1]\n",
    "\n",
    "                        belong_to_other_group = False\n",
    "                        belong_to_this_group = False\n",
    "\n",
    "                        # The text located 'in' this polygon => include\n",
    "                        in_polygon_arg = np.logical_and(labeled[0:global_res_probability[legend].shape[0], 0:global_res_probability[legend].shape[1]] == object_traverse, global_res_probability[legend] >= 0.5)\n",
    "                        in_polygon_bool = (True in in_polygon_arg)\n",
    "                        if in_polygon_bool == True:\n",
    "                            belong_to_other_group = False\n",
    "                            belong_to_this_group = True\n",
    "\n",
    "                        # The text located 'nearby' this polygon => include (especially for small polygons, where legends are labeled outside)\n",
    "                        if belong_to_other_group == False:\n",
    "                            center_placeholder = np.array([[center_x, center_y]])\n",
    "                            center_placeholder = np.repeat(center_placeholder, len(global_confidence[legend]), axis=0)\n",
    "                            distances_2_depot = np.sqrt(np.sum((global_confidence[legend]-center_placeholder)**2,axis=1))\n",
    "                            min_distance_to_self = np.min(distances_2_depot)\n",
    "                            \n",
    "                            if min_distance_to_self < distance_threshold:\n",
    "                                belong_to_other_group = False\n",
    "                                belong_to_this_group = True\n",
    "\n",
    "                        # The counter-text located 'in' this polygon => exclude\n",
    "                        if belong_to_other_group == False:\n",
    "                            center_placeholder = np.array([[center_x, center_y]])\n",
    "                            center_placeholder = np.repeat(center_placeholder, len(global_confidence[counter_legend]), axis=0)\n",
    "                            distances_2_depot = np.sqrt(np.sum((global_confidence[counter_legend]-center_placeholder)**2,axis=1))\n",
    "                            min_distance_to_counter = np.min(distances_2_depot)\n",
    "                            \n",
    "                            in_polygon_arg = np.logical_and(labeled[0:global_res_probability[counter_legend].shape[0], 0:global_res_probability[counter_legend].shape[1]] == object_traverse, global_res_probability[counter_legend] >= 0.75)\n",
    "                            in_polygon_bool = (True in in_polygon_arg)\n",
    "                            if in_polygon_bool == True:\n",
    "                                belong_to_other_group = True\n",
    "                                belong_to_this_group = False\n",
    "                            \n",
    "\n",
    "                        if belong_to_other_group == False and belong_to_this_group == False:\n",
    "                            #if min_distance_to_self/confidence_to_self < (min_distance_to_counter/confidence_to_counter)*1.33:\n",
    "                            if min_distance_to_self < (min_distance_to_counter)*2.0:\n",
    "                                belong_to_this_group = True\n",
    "\n",
    "\n",
    "                        if belong_to_this_group == True and belong_to_other_group == False :\n",
    "                            # create a mask to only preserve current legend color in the basemap\n",
    "                            depot_checked_polygon_0 = np.zeros((labeled.shape[0],labeled.shape[1]),dtype=np.uint8)\n",
    "                            depot_checked_polygon_0[np.logical_and(labeled==object_traverse, ans_category[legend]>0)] = 255\n",
    "                            depot_checked_polygon_0 = cv2.bitwise_and(depot_checked_polygon_0, ans_category[legend])\n",
    "                            depot_checked_polygon = cv2.bitwise_or(depot_checked_polygon, depot_checked_polygon_0)\n",
    "                            depot_got = depot_got+1\n",
    "\n",
    "\n",
    "                    #print('updated against - '+legend_name[counter_legend])\n",
    "                    #plt.imshow(save_region_temp)\n",
    "                    #plt.show()\n",
    "                    #plt.imshow(depot_checked_polygon)\n",
    "                    #plt.show()\n",
    "                    img_ans_v1 = cv2.bitwise_and(ans_category[legend], depot_checked_polygon)\n",
    "                    img_ans_v1 = cv2.bitwise_or(img_ans_v1, save_region_temp)\n",
    "                    #plt.imshow(img_ans_v1)\n",
    "                    #plt.show()\n",
    "\n",
    "                    return img_ans_v1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                def compare_against_competitor(legend):\n",
    "                    updated_region = np.copy(ans_category[legend])\n",
    "\n",
    "                    for counter_list_id in range(0, len(comparison_target[legend])):\n",
    "                        counter_legend = comparison_target[legend][counter_list_id]\n",
    "                        #print(legend_name[legend]+' <-> '+legend_name[counter_legend])\n",
    "                        img_ans_v1 = update_based_on_text(legend, counter_legend)\n",
    "                        ban_region = cv2.subtract(ans_category[legend], img_ans_v1)\n",
    "                        updated_region = cv2.subtract(updated_region, ban_region)\n",
    "                    \n",
    "                    \n",
    "                    # remove noisy white pixel\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                    opening = cv2.morphologyEx(updated_region, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                    updated_region=cv2.threshold(opening, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "                    \n",
    "                    if poly_counter <= 40:\n",
    "                        if np.unique(updated_region).shape[0] != 2 or (np.sum(updated_region)/np.unique(updated_region)[1]) / (np.sum(ans_category[legend])/np.unique(ans_category[legend])[1]) < 0.0005:\n",
    "                            print(legend_name[legend]+' rollback...')\n",
    "                            updated_region = np.copy(ans_category[legend])\n",
    "                    else:\n",
    "                        if np.unique(updated_region).shape[0] != 2 or (np.sum(updated_region)/np.unique(updated_region)[1]) / (np.sum(ans_category[legend])/np.unique(ans_category[legend])[1]) < 0.0001:\n",
    "                            print(legend_name[legend]+' rollback...')\n",
    "                            updated_region = np.copy(ans_category[legend])\n",
    "\n",
    "\n",
    "                    if print_intermediate_image == True:\n",
    "                        out_file_path000=os.path.join('intermediate7(2)', map_name, map_name+'_'+legend_name[legend]+'_poly_v6.png')\n",
    "                        cv2.imwrite(out_file_path000, updated_region)\n",
    "\n",
    "                    return legend, updated_region\n",
    "\n",
    "\n",
    "                # multiprocessing\n",
    "                temp_ans_category = np.copy(ans_category)\n",
    "                list_for_multiprocessing = []\n",
    "                for list_id in range(0, len(comparison_needed)):\n",
    "                    legend = comparison_needed[list_id]\n",
    "                    list_for_multiprocessing.append(legend)\n",
    "                print(list_for_multiprocessing)\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    multiprocessing_results = [pool.apply_async(compare_against_competitor, (this_poly,)) for this_poly in list_for_multiprocessing]\n",
    "\n",
    "                    for this_poly in multiprocessing_results:\n",
    "                        legend, updated_region = this_poly.get()\n",
    "                        temp_ans_category[legend] = np.copy(updated_region)\n",
    "\n",
    "                    print('time check _text_v3:', datetime.now()-runningtime_start)\n",
    "                    running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "                    print('text detection finished...')\n",
    "                    ans_category = np.copy(temp_ans_category)\n",
    "\n",
    "\n",
    "\n",
    "            def extraction_step6(legend):\n",
    "                '''\n",
    "                # remove noisy white pixel\n",
    "                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                opening = cv2.morphologyEx(ans_category[legend], cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                ans_category[legend]=cv2.threshold(opening, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "                '''\n",
    "\n",
    "\n",
    "                if np.unique(ans_category[legend]).shape[0] != 2:\n",
    "                    print('extract nothing...')\n",
    "                    ans_category[legend] = np.copy(img_bound)\n",
    "\n",
    "\n",
    "                if True: # print_intermediate_image == True:\n",
    "                    out_file_path0='intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_v7.png'\n",
    "                    cv2.imwrite(out_file_path0, ans_category[legend])\n",
    "\n",
    "                # convert the grayscale image to binary image\n",
    "                pred_binary_raster = ans_category[legend].astype(float) / 255\n",
    "\n",
    "                # print\n",
    "                #print('predicted binary raster:')\n",
    "                #print('shape:', pred_binary_raster.shape)\n",
    "                #print('unique value(s):', np.unique(pred_binary_raster))\n",
    "                #print(map_name, '/', legend_name[legend])\n",
    "                print(legend_name[legend])\n",
    "\n",
    "                # plot the raster and save it\n",
    "                plt.imshow(pred_binary_raster)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "                # save the raster into a .tif file\n",
    "                out_file_path='intermediate7(2)/'+map_name+'_'+legend_name[legend]+'_poly.tif' # output\n",
    "                pred_binary_raster=pred_binary_raster.astype('uint16')\n",
    "                cv2.imwrite(out_file_path, pred_binary_raster)\n",
    "\n",
    "                # convert the image to a binary raster .tif\n",
    "                raster = rasterio.open(file_path)\n",
    "                transform = raster.transform\n",
    "                # array     = raster.read(1)\n",
    "                crs       = raster.crs \n",
    "                width     = raster.width \n",
    "                height    = raster.height \n",
    "\n",
    "                raster.close()\n",
    "\n",
    "                raster = rasterio.open(out_file_path)   \n",
    "                array  = raster.read(1)\n",
    "                raster.close()\n",
    "                with rasterio.open(out_file_path, 'w', \n",
    "                                   driver    = 'GTIFF', \n",
    "                                   transform = transform, \n",
    "                                   dtype     = rasterio.uint8, \n",
    "                                   count     = 1, \n",
    "                                   compress  = 'lzw', \n",
    "                                   crs       = crs, \n",
    "                                   width     = width, \n",
    "                                   height    = height) as dst:\n",
    "\n",
    "                    dst.write(array, indexes=1)\n",
    "                    dst.close()\n",
    "                    \n",
    "                return legend, pred_binary_raster\n",
    "\n",
    "\n",
    "            # multiprocessing_step6\n",
    "            with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                multiprocessing_results = [pool.apply_async(extraction_step6, (this_poly,)) for this_poly in range(range_min, range_max)]\n",
    "\n",
    "                for this_poly in multiprocessing_results:\n",
    "                    legend, pred_binary_raster = this_poly.get()\n",
    "\n",
    "            print('time check _v6:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "        if os.path.isfile('intermediate7(2)/'+'running_time_record_v2.csv') == False:\n",
    "            with open('intermediate7(2)/'+'running_time_record_v2.csv','w') as fd:\n",
    "                fd.write('File,checkpoint_1,checkpoint_2,checkpoint_3,checkpoint_4,checkpoint_5,checkpoint_6,\\n')\n",
    "                fd.close()\n",
    "        with open('intermediate7(2)/'+'running_time_record_v2.csv','a') as fd:\n",
    "            fd.write(map_name+',')\n",
    "            for rtc in range(0, len(running_time_v)):\n",
    "                fd.write(str(running_time_v[rtc])+',')\n",
    "            fd.write('\\n')\n",
    "            fd.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afa705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb321cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e36b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "50de70a9325bb4be4ddc676c1523ee623a475b4dc3ab526e9893c4da49819292"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
